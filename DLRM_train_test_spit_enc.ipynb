{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitkagglenewpipenv345dfe1713484c20b6863d1100cfe670",
   "display_name": "Python 3.6.9 64-bit ('kaggle_new': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a model with pre-defined (and saved) train / test datasets\n",
    "# here we repeat the steps from DLRM_train_test_split but prepare the data for the model by (i) method # used in pytorch example and (ii) use Integer Encoding (from kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>unix_timestamp</th>\n      <th>title</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>847434962</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1106635946</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>1510577970</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1305696483</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   user_id  movie_id  rating  unix_timestamp             title  \\\n0        1         1     4.0       964982703  Toy Story (1995)   \n1        5         1     4.0       847434962  Toy Story (1995)   \n2        7         1     4.5      1106635946  Toy Story (1995)   \n3       15         1     2.5      1510577970  Toy Story (1995)   \n4       17         1     4.5      1305696483  Toy Story (1995)   \n\n                                         genre  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1  Adventure|Animation|Children|Comedy|Fantasy  \n2  Adventure|Animation|Children|Comedy|Fantasy  \n3  Adventure|Animation|Children|Comedy|Fantasy  \n4  Adventure|Animation|Children|Comedy|Fantasy  "
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data ml-latest-small\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np \n",
    "zf = zipfile.ZipFile('/home/elena/Downloads/ml-latest-small.zip')\n",
    "# reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(zf.open('ml-latest-small/ratings.csv'), names=r_cols)\n",
    "m_cols=['movie_id', 'title', 'genre']\n",
    "movies = pd.read_csv(zf.open('ml-latest-small/movies.csv'), names=m_cols)\n",
    "# merging ratings and movies\n",
    "ratings=pd.merge(ratings,movies,on='movie_id')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(ratings):\n",
    "    unique_movies = ratings.movie_id.unique() # returns a np array\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)} # indexing movie_id, tart at 0\n",
    "    index_to_movie = {idx: movie for movie, idx in movie_to_index.items()}\n",
    "    new_movies = ratings.movie_id.map(movie_to_index) # replaces movie_id with coresp. index\n",
    "    ratings['movie_index']=new_movies\n",
    "\n",
    "    train=pd.read_pickle('/home/elena/Downloads/traindata.pkl')\n",
    "    test=pd.read_pickle('/home/elena/Downloads/testdata.pkl')\n",
    "    train['movie_index']=train.movie_id.map(movie_to_index)\n",
    "    test['movie_index']=test.movie_id.map(movie_to_index)\n",
    "\n",
    "    X_train=train.drop('rating',axis=1)\n",
    "    X_test=test.drop('rating', axis=1)\n",
    "\n",
    "    y_train = train['rating'].astype(np.float32)\n",
    "    y_test=test['rating'].astype(np.float32)\n",
    "    return (X_train, y_train), (X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test,y_test) = create_dataset(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n      <th>movie_id</th>\n      <th>unix_timestamp</th>\n      <th>title</th>\n      <th>genre</th>\n      <th>movie_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>97717</th>\n      <td>606</td>\n      <td>28</td>\n      <td>M</td>\n      <td>programmer</td>\n      <td>63044</td>\n      <td>3462</td>\n      <td>1171501099</td>\n      <td>Modern Times (1936)</td>\n      <td>Comedy|Drama|Romance</td>\n      <td>1185</td>\n    </tr>\n    <tr>\n      <th>100124</th>\n      <td>610</td>\n      <td>22</td>\n      <td>M</td>\n      <td>student</td>\n      <td>21227</td>\n      <td>8914</td>\n      <td>1493845360</td>\n      <td>Primer (2004)</td>\n      <td>Drama|Sci-Fi</td>\n      <td>2266</td>\n    </tr>\n    <tr>\n      <th>25952</th>\n      <td>180</td>\n      <td>22</td>\n      <td>F</td>\n      <td>administrator</td>\n      <td>60202</td>\n      <td>1196</td>\n      <td>1270237862</td>\n      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n      <td>Action|Adventure|Sci-Fi</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>25871</th>\n      <td>178</td>\n      <td>26</td>\n      <td>M</td>\n      <td>other</td>\n      <td>49512</td>\n      <td>2231</td>\n      <td>1163673637</td>\n      <td>Rounders (1998)</td>\n      <td>Drama</td>\n      <td>2183</td>\n    </tr>\n    <tr>\n      <th>97255</th>\n      <td>605</td>\n      <td>33</td>\n      <td>M</td>\n      <td>engineer</td>\n      <td>33716</td>\n      <td>1588</td>\n      <td>1277094877</td>\n      <td>George of the Jungle (1997)</td>\n      <td>Children|Comedy</td>\n      <td>1495</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        user_id  age sex     occupation zip_code  movie_id  unix_timestamp  \\\n97717       606   28   M     programmer    63044      3462      1171501099   \n100124      610   22   M        student    21227      8914      1493845360   \n25952       180   22   F  administrator    60202      1196      1270237862   \n25871       178   26   M          other    49512      2231      1163673637   \n97255       605   33   M       engineer    33716      1588      1277094877   \n\n                                                    title  \\\n97717                                 Modern Times (1936)   \n100124                                      Primer (2004)   \n25952   Star Wars: Episode V - The Empire Strikes Back...   \n25871                                     Rounders (1998)   \n97255                         George of the Jungle (1997)   \n\n                          genre  movie_index  \n97717      Comedy|Drama|Romance         1185  \n100124             Drama|Sci-Fi         2266  \n25952   Action|Adventure|Sci-Fi           68  \n25871                     Drama         2183  \n97255           Children|Comedy         1495  "
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Implementation \n",
    "from keras.layers import Input, Embedding, Concatenate, Flatten, Dense, Dot, Add, Multiply, Subtract, Average\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method):\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    # Embeddings\n",
    "    user_embedded = Embedding(user_max_cat_value+1, user_embedding_dim, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "    movie_embedded = Embedding(movie_max_cat_value+1, movie_embedding_dim, \n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "    # merging the embeddings\n",
    "    if merging_method=='concatenate':\n",
    "        merged = Concatenate()([user_embedded, movie_embedded])\n",
    "    if merging_method=='dot_product':\n",
    "        merged =Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedded, movie_embedded])\n",
    "    if merging_method=='add':\n",
    "        merged =Add()([user_embedded, movie_embedded])\n",
    "    if merging_method=='substract':\n",
    "        merged=Subtract()([user_embedded, movie_embedded])\n",
    "    if merging_method=='multiply':\n",
    "        merged=Multiply()([user_embedded, movie_embedded])\n",
    "    if merging_method=='average':\n",
    "        merged=Average()([user_embedded, movie_embedded])\n",
    "    out = Flatten()(merged)\n",
    "\n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "        out = Dense(n_hidden, activation='relu')(out)\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = Dense(1, activation='linear', name='prediction')(out)\n",
    "    model = Model(inputs = [user_id_input, movie_id_input],outputs = out)\n",
    "    model.compile(optimizer = 'Adam',loss='MSE',metrics=['MAE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the models used\n",
    "hidden_units = (100,50) #same as in pytorch model\n",
    "movie_embedding_dim = 50 #same as in pytorch model\n",
    "user_embedding_dim = 50  #same as in pytorch model\n",
    "user_max_cat_value = ratings.user_id.max()\n",
    "movie_max_cat_value=max(X_train.movie_index.max(), X_test.movie_index.max())\n",
    "es=EarlyStopping(monitor='val_MAE', min_delta=0, patience=0, verbose=0, mode='min', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 3s - loss: 3.2219 - MAE: 1.3146 - val_loss: 0.7871 - val_MAE: 0.6871\nEpoch 2/10\n - 3s - loss: 0.7327 - MAE: 0.6584 - val_loss: 0.7689 - val_MAE: 0.6761\nEpoch 3/10\n - 3s - loss: 0.6935 - MAE: 0.6386 - val_loss: 0.7683 - val_MAE: 0.6747\nEpoch 4/10\n - 3s - loss: 0.6786 - MAE: 0.6297 - val_loss: 0.7726 - val_MAE: 0.6728\nEpoch 5/10\n - 3s - loss: 0.6666 - MAE: 0.6232 - val_loss: 0.7697 - val_MAE: 0.6755\n"
    }
   ],
   "source": [
    "model_concatenate=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='concatenate')\n",
    "# model_concatenate.summary(line_length=88)\n",
    "trained_model_concatenate= model_concatenate.fit(x=[X_train.user_id, X_train.movie_index], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_index],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to \n",
    "#  Epch 4/19 - 48s - loss: 0.6777 - MAE: 0.6295 - val_loss: 0.7709 - val_MAE: 0.6740"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 3s - loss: 4.3300 - MAE: 1.6309 - val_loss: 1.0839 - val_MAE: 0.8247\nEpoch 2/10\n - 3s - loss: 1.0619 - MAE: 0.8205 - val_loss: 1.0836 - val_MAE: 0.8289\n"
    }
   ],
   "source": [
    "model_dot=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='dot_product')\n",
    "trained_model_dot= model_dot.fit(x=[X_train.user_id, X_train.movie_index], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_index],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to without data prep\n",
    "# Epoch 2/10  - 57s - loss: 1.0672 - MAE: 0.8238 - val_loss: 1.0869 - val_MAE: 0.8376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 3s - loss: 3.2192 - MAE: 1.3174 - val_loss: 0.7944 - val_MAE: 0.6886\nEpoch 2/10\n - 3s - loss: 0.7339 - MAE: 0.6592 - val_loss: 0.7746 - val_MAE: 0.6791\nEpoch 3/10\n - 3s - loss: 0.6922 - MAE: 0.6377 - val_loss: 0.7754 - val_MAE: 0.6776\nEpoch 4/10\n - 3s - loss: 0.6730 - MAE: 0.6267 - val_loss: 0.7746 - val_MAE: 0.6755\nEpoch 5/10\n - 3s - loss: 0.6584 - MAE: 0.6184 - val_loss: 0.7721 - val_MAE: 0.6755\n"
    }
   ],
   "source": [
    "model_add=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='add')\n",
    "trained_model_add= model_add.fit(x=[X_train.user_id, X_train.movie_index], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_index],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to without data prep\n",
    "# Epoch 3/10 - 32s - loss: 0.6899 - MAE: 0.6363 - val_loss: 0.7743 - val_MAE: 0.6801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 3.1736 - MAE: 1.3069 - val_loss: 0.7937 - val_MAE: 0.6889\nEpoch 2/10\n - 3s - loss: 0.7325 - MAE: 0.6587 - val_loss: 0.7741 - val_MAE: 0.6762\nEpoch 3/10\n - 3s - loss: 0.6919 - MAE: 0.6372 - val_loss: 0.7730 - val_MAE: 0.6760\nEpoch 4/10\n - 3s - loss: 0.6740 - MAE: 0.6280 - val_loss: 0.7713 - val_MAE: 0.6751\nEpoch 5/10\n - 3s - loss: 0.6593 - MAE: 0.6190 - val_loss: 0.7709 - val_MAE: 0.6738\nEpoch 6/10\n - 3s - loss: 0.6457 - MAE: 0.6108 - val_loss: 0.7733 - val_MAE: 0.6769\n"
    }
   ],
   "source": [
    "model_substract=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='substract')\n",
    "trained_model_substract= model_substract.fit(x=[X_train.user_id, X_train.movie_index], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_index],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to without data prep\n",
    "# Epoch 7/10  - 46s - loss: 0.6186 - MAE: 0.5960 - val_loss: 0.7775 - val_MAE: 0.6773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 3s - loss: 4.4019 - MAE: 1.6439 - val_loss: 1.0738 - val_MAE: 0.8216\nEpoch 2/10\n - 3s - loss: 0.9384 - MAE: 0.7617 - val_loss: 0.8787 - val_MAE: 0.7299\nEpoch 3/10\n - 3s - loss: 0.4896 - MAE: 0.5309 - val_loss: 0.8846 - val_MAE: 0.7308\n"
    }
   ],
   "source": [
    "model_multiply=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='multiply')\n",
    "history_multiply= model_multiply.fit(x=[X_train.user_id, X_train.movie_index], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_index],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to without data prep\n",
    "# Epoch 3/10  - 46s - loss: 0.4674 - MAE: 0.5177 - val_loss: 0.8758 - val_MAE: 0.7270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "User #1 has rated 232 movies (avg. rating = 4.4):\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>unix_timestamp</th>\n      <th>title</th>\n      <th>genre</th>\n      <th>movie_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16250</th>\n      <td>1</td>\n      <td>5060</td>\n      <td>5.0</td>\n      <td>964984002</td>\n      <td>M*A*S*H (a.k.a. MASH) (1970)</td>\n      <td>Comedy|Drama|War</td>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>14053</th>\n      <td>1</td>\n      <td>2872</td>\n      <td>5.0</td>\n      <td>964981680</td>\n      <td>Excalibur (1981)</td>\n      <td>Adventure|Fantasy</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>9066</th>\n      <td>1</td>\n      <td>1291</td>\n      <td>5.0</td>\n      <td>964981909</td>\n      <td>Indiana Jones and the Last Crusade (1989)</td>\n      <td>Action|Adventure</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>9206</th>\n      <td>1</td>\n      <td>1298</td>\n      <td>5.0</td>\n      <td>964984086</td>\n      <td>Pink Floyd: The Wall (1982)</td>\n      <td>Drama|Musical</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>14254</th>\n      <td>1</td>\n      <td>2948</td>\n      <td>5.0</td>\n      <td>964982191</td>\n      <td>From Russia with Love (1963)</td>\n      <td>Action|Adventure|Thriller</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12997</th>\n      <td>1</td>\n      <td>2617</td>\n      <td>2.0</td>\n      <td>964982588</td>\n      <td>Mummy, The (1999)</td>\n      <td>Action|Adventure|Comedy|Fantasy|Horror|Thriller</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>11663</th>\n      <td>1</td>\n      <td>2253</td>\n      <td>2.0</td>\n      <td>964981775</td>\n      <td>Toys (1992)</td>\n      <td>Comedy|Fantasy</td>\n      <td>143</td>\n    </tr>\n    <tr>\n      <th>11991</th>\n      <td>1</td>\n      <td>2338</td>\n      <td>2.0</td>\n      <td>964983546</td>\n      <td>I Still Know What You Did Last Summer (1998)</td>\n      <td>Horror|Mystery|Thriller</td>\n      <td>148</td>\n    </tr>\n    <tr>\n      <th>12117</th>\n      <td>1</td>\n      <td>2389</td>\n      <td>2.0</td>\n      <td>964983094</td>\n      <td>Psycho (1998)</td>\n      <td>Crime|Horror|Thriller</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>15190</th>\n      <td>1</td>\n      <td>3176</td>\n      <td>1.0</td>\n      <td>964983504</td>\n      <td>Talented Mr. Ripley, The (1999)</td>\n      <td>Drama|Mystery|Thriller</td>\n      <td>205</td>\n    </tr>\n  </tbody>\n</table>\n<p>232 rows × 7 columns</p>\n</div>",
      "text/plain": "       user_id  movie_id  rating  unix_timestamp  \\\n16250        1      5060     5.0       964984002   \n14053        1      2872     5.0       964981680   \n9066         1      1291     5.0       964981909   \n9206         1      1298     5.0       964984086   \n14254        1      2948     5.0       964982191   \n...        ...       ...     ...             ...   \n12997        1      2617     2.0       964982588   \n11663        1      2253     2.0       964981775   \n11991        1      2338     2.0       964983546   \n12117        1      2389     2.0       964983094   \n15190        1      3176     1.0       964983504   \n\n                                              title  \\\n16250                  M*A*S*H (a.k.a. MASH) (1970)   \n14053                              Excalibur (1981)   \n9066      Indiana Jones and the Last Crusade (1989)   \n9206                    Pink Floyd: The Wall (1982)   \n14254                  From Russia with Love (1963)   \n...                                             ...   \n12997                             Mummy, The (1999)   \n11663                                   Toys (1992)   \n11991  I Still Know What You Did Last Summer (1998)   \n12117                                 Psycho (1998)   \n15190               Talented Mr. Ripley, The (1999)   \n\n                                                 genre  movie_index  \n16250                                 Comedy|Drama|War          231  \n14053                                Adventure|Fantasy          185  \n9066                                  Action|Adventure           89  \n9206                                     Drama|Musical           90  \n14254                        Action|Adventure|Thriller          190  \n...                                                ...          ...  \n12997  Action|Adventure|Comedy|Fantasy|Horror|Thriller          170  \n11663                                   Comedy|Fantasy          143  \n11991                          Horror|Mystery|Thriller          148  \n12117                            Crime|Horror|Thriller          152  \n15190                           Drama|Mystery|Thriller          205  \n\n[232 rows x 7 columns]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User 1\n",
    "uid = 1\n",
    "user_ratings = ratings[ratings.user_id==uid]\n",
    "print(\"User #{} has rated {} movies (avg. rating = {:.1f}):\".format(\n",
    "    uid, len(user_ratings), user_ratings['rating'].mean(),\n",
    "))\n",
    "user_ratings.sort_values(by='rating', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting for movies from the test data\n",
    "movies_from_test=X_test.movie_id[X_test.user_id==uid].unique()\n",
    "# prediction \n",
    "pred_concatenate=model_concatenate.predict([[uid]*len(movies_from_test),movies_from_test])\n",
    "pred_dot=model_dot.predict([[uid]*len(movies_from_test),movies_from_test])\n",
    "pred_add=model_add.predict([[uid]*len(movies_from_test),movies_from_test])\n",
    "pred_substract=model_substract.predict([[uid]*len(movies_from_test),movies_from_test])\n",
    "pred_multiply=model_multiply.predict([[uid]*len(movies_from_test),movies_from_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n      <th>movie_id</th>\n      <th>unix_timestamp</th>\n      <th>title</th>\n      <th>genre</th>\n      <th>movie_index</th>\n      <th>model_concatenate</th>\n      <th>model_dot</th>\n      <th>model_add</th>\n      <th>model_substract</th>\n      <th>model_multiply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>156</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n      <td>2427</td>\n      <td>964982242</td>\n      <td>Thin Red Line, The (1998)</td>\n      <td>Action|Drama|War</td>\n      <td>156</td>\n      <td>5.259588</td>\n      <td>3.453155</td>\n      <td>5.149864</td>\n      <td>5.198905</td>\n      <td>4.512282</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n      <td>3578</td>\n      <td>964980668</td>\n      <td>Gladiator (2000)</td>\n      <td>Action|Adventure|Drama</td>\n      <td>219</td>\n      <td>5.051665</td>\n      <td>3.467472</td>\n      <td>5.080530</td>\n      <td>4.647391</td>\n      <td>3.503902</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n      <td>423</td>\n      <td>964982363</td>\n      <td>Blown Away (1994)</td>\n      <td>Action|Thriller</td>\n      <td>23</td>\n      <td>5.015301</td>\n      <td>3.456332</td>\n      <td>5.042354</td>\n      <td>4.842852</td>\n      <td>4.371572</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n      <td>2797</td>\n      <td>964981710</td>\n      <td>Big (1988)</td>\n      <td>Comedy|Drama|Fantasy|Romance</td>\n      <td>182</td>\n      <td>4.916557</td>\n      <td>3.531247</td>\n      <td>4.847631</td>\n      <td>4.948329</td>\n      <td>3.343365</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n      <td>2899</td>\n      <td>964982703</td>\n      <td>Gulliver's Travels (1939)</td>\n      <td>Adventure|Animation|Children</td>\n      <td>186</td>\n      <td>4.896867</td>\n      <td>3.489475</td>\n      <td>4.976969</td>\n      <td>5.029078</td>\n      <td>4.093573</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     user_id  age sex  occupation zip_code  movie_id  unix_timestamp  \\\n156        1   24   M  technician    85711      2427       964982242   \n219        1   24   M  technician    85711      3578       964980668   \n23         1   24   M  technician    85711       423       964982363   \n182        1   24   M  technician    85711      2797       964981710   \n186        1   24   M  technician    85711      2899       964982703   \n\n                         title                         genre  movie_index  \\\n156  Thin Red Line, The (1998)              Action|Drama|War          156   \n219           Gladiator (2000)        Action|Adventure|Drama          219   \n23           Blown Away (1994)               Action|Thriller           23   \n182                 Big (1988)  Comedy|Drama|Fantasy|Romance          182   \n186  Gulliver's Travels (1939)  Adventure|Animation|Children          186   \n\n     model_concatenate  model_dot  model_add  model_substract  model_multiply  \n156           5.259588   3.453155   5.149864         5.198905        4.512282  \n219           5.051665   3.467472   5.080530         4.647391        3.503902  \n23            5.015301   3.456332   5.042354         4.842852        4.371572  \n182           4.916557   3.531247   4.847631         4.948329        3.343365  \n186           4.896867   3.489475   4.976969         5.029078        4.093573  "
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_test=X_test[X_test.user_id==uid]\n",
    "user_data_test['model_concatenate']=pred_concatenate\n",
    "user_data_test['model_dot']=pred_dot\n",
    "user_data_test['model_add']=pred_add\n",
    "user_data_test['model_substract']=pred_substract\n",
    "user_data_test['model_multiply']=pred_multiply\n",
    "user_data_test.sort_values(by='model_concatenate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>top5_model_concatenate</th>\n      <th>top5_model_dot</th>\n      <th>top5_model_add</th>\n      <th>top5_model_substract</th>\n      <th>top5_model_mulitply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12247    Thin Red Line, The (1998)\n12248    Th...</td>\n      <td>12009    Enemy of the State (1998)\n12010    En...</td>\n      <td>12247    Thin Red Line, The (1998)\n12248    Th...</td>\n      <td>12247    Thin Red Line, The (1998)\n12248    Th...</td>\n      <td>7130    Raiders of the Lost Ark (Indiana Jones...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15656    Gladiator (2000)\n15657    Gladiator (...</td>\n      <td>11104    Jungle Book, The (1967)\n11105    Jung...</td>\n      <td>15656    Gladiator (2000)\n15657    Gladiator (...</td>\n      <td>14078    Gulliver's Travels (1939)\n14079    Gu...</td>\n      <td>8944    Young Frankenstein (1974)\n8945    Youn...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2946    Blown Away (1994)\n2947    Blown Away (...</td>\n      <td>5795    Dumbo (1941)\n5796    Dumbo (1941)\n5797...</td>\n      <td>11104    Jungle Book, The (1967)\n11105    Jung...</td>\n      <td>13732    Big (1988)\n13733    Big (1988)\n13734 ...</td>\n      <td>12247    Thin Red Line, The (1998)\n12248    Th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13732    Big (1988)\n13733    Big (1988)\n13734 ...</td>\n      <td>11293    Indiana Jones and the Temple of Doom ...</td>\n      <td>2946    Blown Away (1994)\n2947    Blown Away (...</td>\n      <td>12394    20 Dates (1998)\n12395    20 Dates (19...</td>\n      <td>2946    Blown Away (1994)\n2947    Blown Away (...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14078    Gulliver's Travels (1939)\n14079    Gu...</td>\n      <td>7130    Raiders of the Lost Ark (Indiana Jones...</td>\n      <td>14078    Gulliver's Travels (1939)\n14079    Gu...</td>\n      <td>11104    Jungle Book, The (1967)\n11105    Jung...</td>\n      <td>12394    20 Dates (1998)\n12395    20 Dates (19...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                              top5_model_concatenate  \\\n0  12247    Thin Red Line, The (1998)\n12248    Th...   \n1  15656    Gladiator (2000)\n15657    Gladiator (...   \n2  2946    Blown Away (1994)\n2947    Blown Away (...   \n3  13732    Big (1988)\n13733    Big (1988)\n13734 ...   \n4  14078    Gulliver's Travels (1939)\n14079    Gu...   \n\n                                      top5_model_dot  \\\n0  12009    Enemy of the State (1998)\n12010    En...   \n1  11104    Jungle Book, The (1967)\n11105    Jung...   \n2  5795    Dumbo (1941)\n5796    Dumbo (1941)\n5797...   \n3  11293    Indiana Jones and the Temple of Doom ...   \n4  7130    Raiders of the Lost Ark (Indiana Jones...   \n\n                                      top5_model_add  \\\n0  12247    Thin Red Line, The (1998)\n12248    Th...   \n1  15656    Gladiator (2000)\n15657    Gladiator (...   \n2  11104    Jungle Book, The (1967)\n11105    Jung...   \n3  2946    Blown Away (1994)\n2947    Blown Away (...   \n4  14078    Gulliver's Travels (1939)\n14079    Gu...   \n\n                                top5_model_substract  \\\n0  12247    Thin Red Line, The (1998)\n12248    Th...   \n1  14078    Gulliver's Travels (1939)\n14079    Gu...   \n2  13732    Big (1988)\n13733    Big (1988)\n13734 ...   \n3  12394    20 Dates (1998)\n12395    20 Dates (19...   \n4  11104    Jungle Book, The (1967)\n11105    Jung...   \n\n                                 top5_model_mulitply  \n0  7130    Raiders of the Lost Ark (Indiana Jones...  \n1  8944    Young Frankenstein (1974)\n8945    Youn...  \n2  12247    Thin Red Line, The (1998)\n12248    Th...  \n3  2946    Blown Away (1994)\n2947    Blown Away (...  \n4  12394    20 Dates (1998)\n12395    20 Dates (19...  "
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name=lambda movie: ratings.title[ratings.movie_id==movie]\n",
    "top5_model_concatenate_test=user_data_test.nlargest(5,'model_concatenate').movie_id.map(movie_name)\n",
    "top5_model_dot_test=user_data_test.nlargest(5,'model_dot').movie_id.map(movie_name)\n",
    "top5_model_add_test=user_data_test.nlargest(5,'model_add').movie_id.map(movie_name)\n",
    "top5_model_substract_test=user_data_test.nlargest(5,'model_substract').movie_id.map(movie_name)\n",
    "top5_model_multiply_test=user_data_test.nlargest(5,'model_multiply').movie_id.map(movie_name)\n",
    "\n",
    "pd.DataFrame({'top5_model_concatenate': top5_model_concatenate_test.values, 'top5_model_dot':top5_model_dot_test.values, 'top5_model_add':  top5_model_add_test.values, 'top5_model_substract': top5_model_substract_test.values, 'top5_model_mulitply': top5_model_multiply_test.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the intersection between the above columns are greater then for DLRM_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now prepare the data using encoding;\n",
    "# in kaggle is was stated: One embedding layer is required for each categorical variable, and the \n",
    "# embedding expects the categories to be ordinal encoded, although no relationship between the \n",
    "# categories is assumed\n",
    "# previous code: columns=['user_id', 'movie_id', 'rating', 'title']\n",
    "# train=train[columns], test=test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(LabelEncoder)\n",
    "# Encoding the variable\n",
    "ratings_enc= ratings.apply(lambda x: d[x.name].fit_transform(x))\n",
    "# Inverse the encoded if needed: ratings_enc.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "# Using the dictionary to label future data\n",
    "train_enc=train.apply(lambda x: d[x.name].transform(x))\n",
    "test_enc=test.apply(lambda x: d[x.name].transform(x))\n",
    "X_train_enc, X_test_enc=train_enc.drop('rating',axis=1), test_enc.drop('rating',axis=1)\n",
    "y_train_enc=train_enc.rating\n",
    "y_test_enc=test_enc.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 3.6856 - MAE: 1.4867 - val_loss: 3.0786 - val_MAE: 1.3585\nEpoch 2/10\n - 4s - loss: 2.8512 - MAE: 1.2985 - val_loss: 3.0467 - val_MAE: 1.3404\nEpoch 3/10\n - 4s - loss: 2.7113 - MAE: 1.2592 - val_loss: 3.0108 - val_MAE: 1.3299\nEpoch 4/10\n - 4s - loss: 2.5990 - MAE: 1.2277 - val_loss: 2.9773 - val_MAE: 1.3238\nEpoch 5/10\n - 4s - loss: 2.4960 - MAE: 1.1997 - val_loss: 2.9910 - val_MAE: 1.3138\nEpoch 6/10\n - 4s - loss: 2.4163 - MAE: 1.1765 - val_loss: 2.9930 - val_MAE: 1.3247\n"
    }
   ],
   "source": [
    "trained_model_concatenate_enc= model_concatenate.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 4.6630 - MAE: 1.7233 - val_loss: 4.3283 - val_MAE: 1.6490\nEpoch 2/10\n - 3s - loss: 4.1099 - MAE: 1.6057 - val_loss: 4.2320 - val_MAE: 1.6342\nEpoch 3/10\n - 3s - loss: 2.8036 - MAE: 1.2483 - val_loss: 4.0573 - val_MAE: 1.5719\nEpoch 4/10\n - 4s - loss: 1.8753 - MAE: 0.9828 - val_loss: 4.3442 - val_MAE: 1.6293\n"
    }
   ],
   "source": [
    "trained_model_dot_enc= model_dot.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 3.7912 - MAE: 1.5061 - val_loss: 3.0945 - val_MAE: 1.3574\nEpoch 2/10\n - 3s - loss: 2.8353 - MAE: 1.2928 - val_loss: 3.0619 - val_MAE: 1.3439\nEpoch 3/10\n - 3s - loss: 2.7199 - MAE: 1.2628 - val_loss: 3.0564 - val_MAE: 1.3349\nEpoch 4/10\n - 3s - loss: 2.6495 - MAE: 1.2429 - val_loss: 3.0513 - val_MAE: 1.3389\n"
    }
   ],
   "source": [
    "trained_model_add_enc= model_add.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 3.7466 - MAE: 1.4967 - val_loss: 3.0887 - val_MAE: 1.3615\nEpoch 2/10\n - 3s - loss: 2.8346 - MAE: 1.2934 - val_loss: 3.0448 - val_MAE: 1.3471\nEpoch 3/10\n - 3s - loss: 2.7029 - MAE: 1.2570 - val_loss: 3.0510 - val_MAE: 1.3465\nEpoch 4/10\n - 3s - loss: 2.6026 - MAE: 1.2292 - val_loss: 3.0385 - val_MAE: 1.3368\nEpoch 5/10\n - 3s - loss: 2.4852 - MAE: 1.1970 - val_loss: 3.0578 - val_MAE: 1.3298\nEpoch 6/10\n - 4s - loss: 2.3384 - MAE: 1.1562 - val_loss: 3.0739 - val_MAE: 1.3417\n"
    }
   ],
   "source": [
    "trained_model_substract_enc= model_substract.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 3s - loss: 4.4342 - MAE: 1.6637 - val_loss: 3.6382 - val_MAE: 1.4878\nEpoch 2/10\n - 3s - loss: 2.5127 - MAE: 1.2126 - val_loss: 3.5459 - val_MAE: 1.4560\nEpoch 3/10\n - 3s - loss: 1.2740 - MAE: 0.8484 - val_loss: 3.6570 - val_MAE: 1.4843\n"
    }
   ],
   "source": [
    "trained_model_multiply_enc= model_multiply.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUCH WORSE MAE!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}