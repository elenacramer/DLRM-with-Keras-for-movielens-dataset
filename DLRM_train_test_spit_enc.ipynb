{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitkagglenewpipenv345dfe1713484c20b6863d1100cfe670",
   "display_name": "Python 3.6.9 64-bit ('kaggle_new': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a model with pre-defined (and saved) train / test datasets\n",
    "# here we repeat the steps from DLRM_train_test_split but prepare the data for the model by (i) method # used in pytorch example and (ii) use Integer Encoding (from kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>unix_timestamp</th>\n      <th>title</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>847434962</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1106635946</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>1510577970</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1305696483</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   user_id  movie_id  rating  unix_timestamp             title  \\\n0        1         1     4.0       964982703  Toy Story (1995)   \n1        5         1     4.0       847434962  Toy Story (1995)   \n2        7         1     4.5      1106635946  Toy Story (1995)   \n3       15         1     2.5      1510577970  Toy Story (1995)   \n4       17         1     4.5      1305696483  Toy Story (1995)   \n\n                                         genre  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1  Adventure|Animation|Children|Comedy|Fantasy  \n2  Adventure|Animation|Children|Comedy|Fantasy  \n3  Adventure|Animation|Children|Comedy|Fantasy  \n4  Adventure|Animation|Children|Comedy|Fantasy  "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data ml-latest-small\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np \n",
    "zf = zipfile.ZipFile('/home/elena/Downloads/ml-latest-small.zip')\n",
    "# reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(zf.open('ml-latest-small/ratings.csv'), names=r_cols)\n",
    "m_cols=['movie_id', 'title', 'genre']\n",
    "movies = pd.read_csv(zf.open('ml-latest-small/movies.csv'), names=m_cols)\n",
    "# merging ratings and movies\n",
    "ratings=pd.merge(ratings,movies,on='movie_id')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    if top is not None:\n",
    "        ratings.groupby('user_id')['rating'].count()\n",
    "    \n",
    "    unique_users = ratings.user_id.unique()\n",
    "    older_users = ratings.user_id\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    # enumerate(unique_users) returns index_of_user_id and user_id, so new= ndex_of_user_id, old=user_id\n",
    "    new_users = ratings.user_id.map(user_to_index)\n",
    "    \n",
    "    unique_movies = ratings.movie_id.unique()\n",
    "    older_movies = ratings.movie_id\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)}\n",
    "    new_movies = ratings.movie_id.map(movie_to_index)\n",
    "    \n",
    "    n_users = unique_users.shape[0]\n",
    "    n_movies = unique_movies.shape[0]\n",
    "    \n",
    "    X = pd.DataFrame({'user_id': new_users,'user_id_old': ratings.user_id, 'movie_id': new_movies, 'movie_id_old': ratings.movie_id, 'title': ratings.title.values})\n",
    "    y = ratings['rating'].astype(np.float32)\n",
    "    return (n_users, n_movies), (X, y), (user_to_index, movie_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, m), (X, y), _ = create_dataset(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test data\n",
    "# data was split and safed! \n",
    "train=pd.read_pickle('/home/elena/Downloads/traindata.pkl')\n",
    "test=pd.read_pickle('/home/elena/Downloads/testdata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>unix_timestamp</th>\n      <th>title</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>97717</th>\n      <td>606</td>\n      <td>28</td>\n      <td>M</td>\n      <td>programmer</td>\n      <td>63044</td>\n      <td>3462</td>\n      <td>4.0</td>\n      <td>1171501099</td>\n      <td>Modern Times (1936)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>100124</th>\n      <td>610</td>\n      <td>22</td>\n      <td>M</td>\n      <td>student</td>\n      <td>21227</td>\n      <td>8914</td>\n      <td>4.0</td>\n      <td>1493845360</td>\n      <td>Primer (2004)</td>\n      <td>Drama|Sci-Fi</td>\n    </tr>\n    <tr>\n      <th>25952</th>\n      <td>180</td>\n      <td>22</td>\n      <td>F</td>\n      <td>administrator</td>\n      <td>60202</td>\n      <td>1196</td>\n      <td>4.0</td>\n      <td>1270237862</td>\n      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n      <td>Action|Adventure|Sci-Fi</td>\n    </tr>\n    <tr>\n      <th>25871</th>\n      <td>178</td>\n      <td>26</td>\n      <td>M</td>\n      <td>other</td>\n      <td>49512</td>\n      <td>2231</td>\n      <td>4.5</td>\n      <td>1163673637</td>\n      <td>Rounders (1998)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>97255</th>\n      <td>605</td>\n      <td>33</td>\n      <td>M</td>\n      <td>engineer</td>\n      <td>33716</td>\n      <td>1588</td>\n      <td>4.0</td>\n      <td>1277094877</td>\n      <td>George of the Jungle (1997)</td>\n      <td>Children|Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        user_id  age sex     occupation zip_code  movie_id  rating  \\\n97717       606   28   M     programmer    63044      3462     4.0   \n100124      610   22   M        student    21227      8914     4.0   \n25952       180   22   F  administrator    60202      1196     4.0   \n25871       178   26   M          other    49512      2231     4.5   \n97255       605   33   M       engineer    33716      1588     4.0   \n\n        unix_timestamp                                              title  \\\n97717       1171501099                                Modern Times (1936)   \n100124      1493845360                                      Primer (2004)   \n25952       1270237862  Star Wars: Episode V - The Empire Strikes Back...   \n25871       1163673637                                    Rounders (1998)   \n97255       1277094877                        George of the Jungle (1997)   \n\n                          genre  \n97717      Comedy|Drama|Romance  \n100124             Drama|Sci-Fi  \n25952   Action|Adventure|Sci-Fi  \n25871                     Drama  \n97255           Children|Comedy  "
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['user_id', 'movie_id', 'rating', 'title']\n",
    "train=train[columns]\n",
    "test=test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_train, m_train), (X_train, y_train), _ = create_dataset(train)\n",
    "(n_test, m_test), (X_test, y_test), _ = create_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>user_id_old</th>\n      <th>movie_id</th>\n      <th>movie_id_old</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>97717</th>\n      <td>0</td>\n      <td>606</td>\n      <td>0</td>\n      <td>3462</td>\n      <td>Modern Times (1936)</td>\n    </tr>\n    <tr>\n      <th>100124</th>\n      <td>1</td>\n      <td>610</td>\n      <td>1</td>\n      <td>8914</td>\n      <td>Primer (2004)</td>\n    </tr>\n    <tr>\n      <th>25952</th>\n      <td>2</td>\n      <td>180</td>\n      <td>2</td>\n      <td>1196</td>\n      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n    </tr>\n    <tr>\n      <th>25871</th>\n      <td>3</td>\n      <td>178</td>\n      <td>3</td>\n      <td>2231</td>\n      <td>Rounders (1998)</td>\n    </tr>\n    <tr>\n      <th>97255</th>\n      <td>4</td>\n      <td>605</td>\n      <td>4</td>\n      <td>1588</td>\n      <td>George of the Jungle (1997)</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        user_id  user_id_old  movie_id  movie_id_old  \\\n97717         0          606         0          3462   \n100124        1          610         1          8914   \n25952         2          180         2          1196   \n25871         3          178         3          2231   \n97255         4          605         4          1588   \n\n                                                    title  \n97717                                 Modern Times (1936)  \n100124                                      Primer (2004)  \n25952   Star Wars: Episode V - The Empire Strikes Back...  \n25871                                     Rounders (1998)  \n97255                         George of the Jungle (1997)  "
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Embeddings: 610 users, 8762 movies\nDataset shape: (75627, 5)\nTarget shape: (75627,)\n"
    }
   ],
   "source": [
    "print(f'Embeddings: {n_train} users, {m_train} movies')\n",
    "print(f'Dataset shape: {X_train.shape}')\n",
    "print(f'Target shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Test Data: 610 users, 5672 movies\nDataset shape: (25209, 5)\nTarget shape: (25209,)\n"
    }
   ],
   "source": [
    "print(f'Test Data: {n_test} users, {m_test} movies')\n",
    "print(f'Dataset shape: {X_test.shape}')\n",
    "print(f'Target shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Implementation \n",
    "from keras.layers import Input, Embedding, Concatenate, Flatten, Dense, Dot, Add, Multiply, Subtract, Average\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method):\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    # Embeddings\n",
    "    user_embedded = Embedding(user_max_cat_value+1, user_embedding_dim, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "    movie_embedded = Embedding(movie_max_cat_value+1, movie_embedding_dim, \n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "    # merging the embeddings\n",
    "    if merging_method=='concatenate':\n",
    "        merged = Concatenate()([user_embedded, movie_embedded])\n",
    "    if merging_method=='dot_product':\n",
    "        merged =Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedded, movie_embedded])\n",
    "    if merging_method=='add':\n",
    "        merged =Add()([user_embedded, movie_embedded])\n",
    "    if merging_method=='substract':\n",
    "        merged=Subtract()([user_embedded, movie_embedded])\n",
    "    if merging_method=='multiply':\n",
    "        merged=Multiply()([user_embedded, movie_embedded])\n",
    "    if merging_method=='average':\n",
    "        merged=Average()([user_embedded, movie_embedded])\n",
    "    out = Flatten()(merged)\n",
    "\n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "        out = Dense(n_hidden, activation='relu')(out)\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = Dense(1, activation='linear', name='prediction')(out)\n",
    "    model = Model(inputs = [user_id_input, movie_id_input],outputs = out)\n",
    "    model.compile(optimizer = 'Adam',loss='MSE',metrics=['MAE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the models used\n",
    "hidden_units = (100,50) #same as in pytorch model\n",
    "movie_embedding_dim = 50 #same as in pytorch model\n",
    "user_embedding_dim = 50  #same as in pytorch model\n",
    "user_max_cat_value = n\n",
    "movie_max_cat_value=m \n",
    "es=EarlyStopping(monitor='val_MAE', min_delta=0, patience=0, verbose=0, mode='min', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 6s - loss: 2.9159 - MAE: 1.2425 - val_loss: 1.3725 - val_MAE: 0.9333\nEpoch 2/10\n - 5s - loss: 0.7310 - MAE: 0.6581 - val_loss: 1.4237 - val_MAE: 0.9466\n"
    }
   ],
   "source": [
    "model_concatenate=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='concatenate')\n",
    "# model_concatenate.summary(line_length=88)\n",
    "trained_model_concatenate= model_concatenate.fit(x=[X_train.user_id, X_train.movie_id], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_id],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. run\n",
    "# Epoch 2/10  - 3s - loss: 0.7313 - MAE: 0.6582 - val_loss: 1.4151 - val_MAE: 0.9443\n",
    "# compare to \n",
    "#  Epch 4/19 - 48s - loss: 0.6777 - MAE: 0.6295 - val_loss: 0.7709 - val_MAE: 0.6740"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 5s - loss: 4.5304 - MAE: 1.6750 - val_loss: 1.0834 - val_MAE: 0.8260\nEpoch 2/10\n - 5s - loss: 1.0752 - MAE: 0.8265 - val_loss: 1.0894 - val_MAE: 0.8339\n"
    }
   ],
   "source": [
    "model_dot=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='dot_product')\n",
    "trained_model_dot= model_dot.fit(x=[X_train.user_id, X_train.movie_id], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_id],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. run\n",
    "# Epoch 2/10  - 3s - loss: 1.0364 - MAE: 0.8117 - val_loss: 1.1419 - val_MAE: 0.8593\n",
    "# compare to without data prep\n",
    "# Epoch 2/10  - 57s - loss: 1.0672 - MAE: 0.8238 - val_loss: 1.0869 - val_MAE: 0.8376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 6s - loss: 3.1761 - MAE: 1.3064 - val_loss: 1.4247 - val_MAE: 0.9541\nEpoch 2/10\n - 5s - loss: 0.7321 - MAE: 0.6580 - val_loss: 1.4546 - val_MAE: 0.9602\n"
    }
   ],
   "source": [
    "model_add=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='add')\n",
    "trained_model_add= model_add.fit(x=[X_train.user_id, X_train.movie_id], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_id],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Run \n",
    "# Epoch 2/10  - 3s - loss: 0.7324 - MAE: 0.6590 - val_loss: 1.4445 - val_MAE: 0.9573\n",
    "# compare to without data prep\n",
    "# Epoch 3/10 - 32s - loss: 0.6899 - MAE: 0.6363 - val_loss: 0.7743 - val_MAE: 0.6801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 5s - loss: 3.0893 - MAE: 1.2854 - val_loss: 1.4392 - val_MAE: 0.9617\nEpoch 2/10\n - 6s - loss: 0.7312 - MAE: 0.6580 - val_loss: 1.4453 - val_MAE: 0.9568\nEpoch 3/10\n - 6s - loss: 0.6913 - MAE: 0.6372 - val_loss: 1.4925 - val_MAE: 0.9708\n"
    }
   ],
   "source": [
    "model_substract=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='substract')\n",
    "trained_model_substract= model_substract.fit(x=[X_train.user_id, X_train.movie_id], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_id],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. run\n",
    "# Epoch 2/10  - 3s - loss: 0.7352 - MAE: 0.6599 - val_loss: 1.4790 - val_MAE: 0.9682\n",
    "# compare to without data prep\n",
    "# Epoch 7/10  - 46s - loss: 0.6186 - MAE: 0.5960 - val_loss: 0.7775 - val_MAE: 0.6773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 6s - loss: 4.5613 - MAE: 1.6909 - val_loss: 1.0838 - val_MAE: 0.8307\nEpoch 2/10\n - 6s - loss: 0.9243 - MAE: 0.7547 - val_loss: 1.2060 - val_MAE: 0.8850\n"
    }
   ],
   "source": [
    "model_multiply=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value, merging_method='multiply')\n",
    "history_multiply= model_multiply.fit(x=[X_train.user_id, X_train.movie_id], y=y_train, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_id],y_test], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. run\n",
    "# Epoch 2/10  - 3s - loss: 0.9186 - MAE: 0.7515 - val_loss: 1.2040 - val_MAE: 0.8827\n",
    "# compare to without data prep\n",
    "# Epoch 3/10  - 46s - loss: 0.4674 - MAE: 0.5177 - val_loss: 0.8758 - val_MAE: 0.7270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "User #1 has rated 232 movies (avg. rating = 4.4):\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>unix_timestamp</th>\n      <th>title</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16250</th>\n      <td>1</td>\n      <td>5060</td>\n      <td>5.0</td>\n      <td>964984002</td>\n      <td>M*A*S*H (a.k.a. MASH) (1970)</td>\n      <td>Comedy|Drama|War</td>\n    </tr>\n    <tr>\n      <th>14053</th>\n      <td>1</td>\n      <td>2872</td>\n      <td>5.0</td>\n      <td>964981680</td>\n      <td>Excalibur (1981)</td>\n      <td>Adventure|Fantasy</td>\n    </tr>\n    <tr>\n      <th>9066</th>\n      <td>1</td>\n      <td>1291</td>\n      <td>5.0</td>\n      <td>964981909</td>\n      <td>Indiana Jones and the Last Crusade (1989)</td>\n      <td>Action|Adventure</td>\n    </tr>\n    <tr>\n      <th>9206</th>\n      <td>1</td>\n      <td>1298</td>\n      <td>5.0</td>\n      <td>964984086</td>\n      <td>Pink Floyd: The Wall (1982)</td>\n      <td>Drama|Musical</td>\n    </tr>\n    <tr>\n      <th>14254</th>\n      <td>1</td>\n      <td>2948</td>\n      <td>5.0</td>\n      <td>964982191</td>\n      <td>From Russia with Love (1963)</td>\n      <td>Action|Adventure|Thriller</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12997</th>\n      <td>1</td>\n      <td>2617</td>\n      <td>2.0</td>\n      <td>964982588</td>\n      <td>Mummy, The (1999)</td>\n      <td>Action|Adventure|Comedy|Fantasy|Horror|Thriller</td>\n    </tr>\n    <tr>\n      <th>11663</th>\n      <td>1</td>\n      <td>2253</td>\n      <td>2.0</td>\n      <td>964981775</td>\n      <td>Toys (1992)</td>\n      <td>Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>11991</th>\n      <td>1</td>\n      <td>2338</td>\n      <td>2.0</td>\n      <td>964983546</td>\n      <td>I Still Know What You Did Last Summer (1998)</td>\n      <td>Horror|Mystery|Thriller</td>\n    </tr>\n    <tr>\n      <th>12117</th>\n      <td>1</td>\n      <td>2389</td>\n      <td>2.0</td>\n      <td>964983094</td>\n      <td>Psycho (1998)</td>\n      <td>Crime|Horror|Thriller</td>\n    </tr>\n    <tr>\n      <th>15190</th>\n      <td>1</td>\n      <td>3176</td>\n      <td>1.0</td>\n      <td>964983504</td>\n      <td>Talented Mr. Ripley, The (1999)</td>\n      <td>Drama|Mystery|Thriller</td>\n    </tr>\n  </tbody>\n</table>\n<p>232 rows × 6 columns</p>\n</div>",
      "text/plain": "       user_id  movie_id  rating  unix_timestamp  \\\n16250        1      5060     5.0       964984002   \n14053        1      2872     5.0       964981680   \n9066         1      1291     5.0       964981909   \n9206         1      1298     5.0       964984086   \n14254        1      2948     5.0       964982191   \n...        ...       ...     ...             ...   \n12997        1      2617     2.0       964982588   \n11663        1      2253     2.0       964981775   \n11991        1      2338     2.0       964983546   \n12117        1      2389     2.0       964983094   \n15190        1      3176     1.0       964983504   \n\n                                              title  \\\n16250                  M*A*S*H (a.k.a. MASH) (1970)   \n14053                              Excalibur (1981)   \n9066      Indiana Jones and the Last Crusade (1989)   \n9206                    Pink Floyd: The Wall (1982)   \n14254                  From Russia with Love (1963)   \n...                                             ...   \n12997                             Mummy, The (1999)   \n11663                                   Toys (1992)   \n11991  I Still Know What You Did Last Summer (1998)   \n12117                                 Psycho (1998)   \n15190               Talented Mr. Ripley, The (1999)   \n\n                                                 genre  \n16250                                 Comedy|Drama|War  \n14053                                Adventure|Fantasy  \n9066                                  Action|Adventure  \n9206                                     Drama|Musical  \n14254                        Action|Adventure|Thriller  \n...                                                ...  \n12997  Action|Adventure|Comedy|Fantasy|Horror|Thriller  \n11663                                   Comedy|Fantasy  \n11991                          Horror|Mystery|Thriller  \n12117                            Crime|Horror|Thriller  \n15190                           Drama|Mystery|Thriller  \n\n[232 rows x 6 columns]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User 1\n",
    "uid = 1\n",
    "user_ratings = ratings[ratings.user_id==uid]\n",
    "print(\"User #{} has rated {} movies (avg. rating = {:.1f}):\".format(\n",
    "    uid, len(user_ratings), user_ratings['rating'].mean(),\n",
    "))\n",
    "user_ratings.sort_values(by='rating', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting for movies from the test data\n",
    "movies_from_test=X_test.movie_id[X_test.user_id_old==uid].unique()\n",
    "# prediction \n",
    "pred_concatenate=model_concatenate.predict([[uid]*len(movies_from_test),movies_from_test])\n",
    "pred_dot=model_dot.predict([[uid]*len(movies_from_test),movies_from_test])\n",
    "pred_add=model_add.predict([[uid]*len(movies_from_test),movies_from_test])\n",
    "pred_substract=model_substract.predict([[uid]*len(movies_from_test),movies_from_test])\n",
    "pred_multiply=model_multiply.predict([[uid]*len(movies_from_test),movies_from_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>title</th>\n      <th>model_concatenate</th>\n      <th>model_dot</th>\n      <th>model_add</th>\n      <th>model_substract</th>\n      <th>model_multiply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>115</th>\n      <td>1</td>\n      <td>1954</td>\n      <td>5.0</td>\n      <td>Rocky (1976)</td>\n      <td>3.951483</td>\n      <td>3.421226</td>\n      <td>3.860736</td>\n      <td>3.863217</td>\n      <td>3.769209</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>1</td>\n      <td>2427</td>\n      <td>5.0</td>\n      <td>Thin Red Line, The (1998)</td>\n      <td>4.188340</td>\n      <td>3.422340</td>\n      <td>3.943762</td>\n      <td>3.956832</td>\n      <td>3.737620</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>151</td>\n      <td>5.0</td>\n      <td>Rob Roy (1995)</td>\n      <td>4.110387</td>\n      <td>3.460751</td>\n      <td>4.457175</td>\n      <td>4.356219</td>\n      <td>3.617298</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>1</td>\n      <td>1282</td>\n      <td>5.0</td>\n      <td>Fantasia (1940)</td>\n      <td>3.653706</td>\n      <td>3.476704</td>\n      <td>3.590794</td>\n      <td>3.459525</td>\n      <td>3.499617</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>1</td>\n      <td>2329</td>\n      <td>5.0</td>\n      <td>American History X (1998)</td>\n      <td>4.042581</td>\n      <td>3.421099</td>\n      <td>3.649195</td>\n      <td>4.041459</td>\n      <td>3.816945</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     user_id  movie_id  rating                      title  model_concatenate  \\\n115        1      1954     5.0               Rocky (1976)           3.951483   \n156        1      2427     5.0  Thin Red Line, The (1998)           4.188340   \n8          1       151     5.0             Rob Roy (1995)           4.110387   \n88         1      1282     5.0            Fantasia (1940)           3.653706   \n147        1      2329     5.0  American History X (1998)           4.042581   \n\n     model_dot  model_add  model_substract  model_multiply  \n115   3.421226   3.860736         3.863217        3.769209  \n156   3.422340   3.943762         3.956832        3.737620  \n8     3.460751   4.457175         4.356219        3.617298  \n88    3.476704   3.590794         3.459525        3.499617  \n147   3.421099   3.649195         4.041459        3.816945  "
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_test=test[test.user_id==uid]\n",
    "user_data_test['model_concatenate']=pred_concatenate\n",
    "user_data_test['model_dot']=pred_dot\n",
    "user_data_test['model_add']=pred_add\n",
    "user_data_test['model_substract']=pred_substract\n",
    "user_data_test['model_multiply']=pred_multiply\n",
    "user_data_test.sort_values(by='rating', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>top5_model_concatenate</th>\n      <th>top5_model_dot</th>\n      <th>top5_model_add</th>\n      <th>top5_model_substract</th>\n      <th>top5_model_mulitply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79094    Harold and Maude (1971)\n79095    Haro...</td>\n      <td>79094    Harold and Maude (1971)\n79095    Haro...</td>\n      <td>70504    Dark Days (2000)\n70505    Dark Days (...</td>\n      <td>79094    Harold and Maude (1971)\n79095    Haro...</td>\n      <td>85367    Story of Women (Affaire de femmes, Un...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85367    Story of Women (Affaire de femmes, Un...</td>\n      <td>70503    Stray Dog (Nora inu) (1949)\nName: tit...</td>\n      <td>85367    Story of Women (Affaire de femmes, Un...</td>\n      <td>85367    Story of Women (Affaire de femmes, Un...</td>\n      <td>59893    The Devil's Advocate (1997)\n59894    ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>70504    Dark Days (2000)\n70505    Dark Days (...</td>\n      <td>53224    Bourne Identity, The (2002)\n53225    ...</td>\n      <td>53224    Bourne Identity, The (2002)\n53225    ...</td>\n      <td>53224    Bourne Identity, The (2002)\n53225    ...</td>\n      <td>53224    Bourne Identity, The (2002)\n53225    ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>59893    The Devil's Advocate (1997)\n59894    ...</td>\n      <td>45702    Fifth Element, The (1997)\n45703    Fi...</td>\n      <td>79094    Harold and Maude (1971)\n79095    Haro...</td>\n      <td>70504    Dark Days (2000)\n70505    Dark Days (...</td>\n      <td>70504    Dark Days (2000)\n70505    Dark Days (...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>53224    Bourne Identity, The (2002)\n53225    ...</td>\n      <td>59893    The Devil's Advocate (1997)\n59894    ...</td>\n      <td>12101    Very Bad Things (1998)\n12102    Very ...</td>\n      <td>12101    Very Bad Things (1998)\n12102    Very ...</td>\n      <td>32998    Aristocats, The (1970)\n32999    Arist...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                              top5_model_concatenate  \\\n0  79094    Harold and Maude (1971)\n79095    Haro...   \n1  85367    Story of Women (Affaire de femmes, Un...   \n2  70504    Dark Days (2000)\n70505    Dark Days (...   \n3  59893    The Devil's Advocate (1997)\n59894    ...   \n4  53224    Bourne Identity, The (2002)\n53225    ...   \n\n                                      top5_model_dot  \\\n0  79094    Harold and Maude (1971)\n79095    Haro...   \n1  70503    Stray Dog (Nora inu) (1949)\nName: tit...   \n2  53224    Bourne Identity, The (2002)\n53225    ...   \n3  45702    Fifth Element, The (1997)\n45703    Fi...   \n4  59893    The Devil's Advocate (1997)\n59894    ...   \n\n                                      top5_model_add  \\\n0  70504    Dark Days (2000)\n70505    Dark Days (...   \n1  85367    Story of Women (Affaire de femmes, Un...   \n2  53224    Bourne Identity, The (2002)\n53225    ...   \n3  79094    Harold and Maude (1971)\n79095    Haro...   \n4  12101    Very Bad Things (1998)\n12102    Very ...   \n\n                                top5_model_substract  \\\n0  79094    Harold and Maude (1971)\n79095    Haro...   \n1  85367    Story of Women (Affaire de femmes, Un...   \n2  53224    Bourne Identity, The (2002)\n53225    ...   \n3  70504    Dark Days (2000)\n70505    Dark Days (...   \n4  12101    Very Bad Things (1998)\n12102    Very ...   \n\n                                 top5_model_mulitply  \n0  85367    Story of Women (Affaire de femmes, Un...  \n1  59893    The Devil's Advocate (1997)\n59894    ...  \n2  53224    Bourne Identity, The (2002)\n53225    ...  \n3  70504    Dark Days (2000)\n70505    Dark Days (...  \n4  32998    Aristocats, The (1970)\n32999    Arist...  "
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name=lambda movie: X.title[X.movie_id==movie]\n",
    "top5_model_concatenate_test=user_data_test.nlargest(5,'model_concatenate').movie_id.map(movie_name)\n",
    "top5_model_dot_test=user_data_test.nlargest(5,'model_dot').movie_id.map(movie_name)\n",
    "top5_model_add_test=user_data_test.nlargest(5,'model_add').movie_id.map(movie_name)\n",
    "top5_model_substract_test=user_data_test.nlargest(5,'model_substract').movie_id.map(movie_name)\n",
    "top5_model_multiply_test=user_data_test.nlargest(5,'model_multiply').movie_id.map(movie_name)\n",
    "\n",
    "pd.DataFrame({'top5_model_concatenate': top5_model_concatenate_test.values, 'top5_model_dot':top5_model_dot_test.values, 'top5_model_add':  top5_model_add_test.values, 'top5_model_substract': top5_model_substract_test.values, 'top5_model_mulitply': top5_model_multiply_test.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the intersection between the above columns are greater then for DLRM_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now prepare the data using encoding;\n",
    "# in kaggle is was stated: One embedding layer is required for each categorical variable, and the \n",
    "# embedding expects the categories to be ordinal encoded, although no relationship between the \n",
    "# categories is assumed\n",
    "# previous code: columns=['user_id', 'movie_id', 'rating', 'title']\n",
    "# train=train[columns], test=test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(LabelEncoder)\n",
    "# Encoding the variable\n",
    "ratings_enc= ratings.apply(lambda x: d[x.name].fit_transform(x))\n",
    "# Inverse the encoded if needed: ratings_enc.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "# Using the dictionary to label future data\n",
    "train_enc=train.apply(lambda x: d[x.name].transform(x))\n",
    "test_enc=test.apply(lambda x: d[x.name].transform(x))\n",
    "X_train_enc, X_test_enc=train_enc.drop('rating',axis=1), test_enc.drop('rating',axis=1)\n",
    "y_train_enc=train_enc.rating\n",
    "y_test_enc=test_enc.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 3.6856 - MAE: 1.4867 - val_loss: 3.0786 - val_MAE: 1.3585\nEpoch 2/10\n - 4s - loss: 2.8512 - MAE: 1.2985 - val_loss: 3.0467 - val_MAE: 1.3404\nEpoch 3/10\n - 4s - loss: 2.7113 - MAE: 1.2592 - val_loss: 3.0108 - val_MAE: 1.3299\nEpoch 4/10\n - 4s - loss: 2.5990 - MAE: 1.2277 - val_loss: 2.9773 - val_MAE: 1.3238\nEpoch 5/10\n - 4s - loss: 2.4960 - MAE: 1.1997 - val_loss: 2.9910 - val_MAE: 1.3138\nEpoch 6/10\n - 4s - loss: 2.4163 - MAE: 1.1765 - val_loss: 2.9930 - val_MAE: 1.3247\n"
    }
   ],
   "source": [
    "trained_model_concatenate_enc= model_concatenate.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 4.6630 - MAE: 1.7233 - val_loss: 4.3283 - val_MAE: 1.6490\nEpoch 2/10\n - 3s - loss: 4.1099 - MAE: 1.6057 - val_loss: 4.2320 - val_MAE: 1.6342\nEpoch 3/10\n - 3s - loss: 2.8036 - MAE: 1.2483 - val_loss: 4.0573 - val_MAE: 1.5719\nEpoch 4/10\n - 4s - loss: 1.8753 - MAE: 0.9828 - val_loss: 4.3442 - val_MAE: 1.6293\n"
    }
   ],
   "source": [
    "trained_model_dot_enc= model_dot.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 3.7912 - MAE: 1.5061 - val_loss: 3.0945 - val_MAE: 1.3574\nEpoch 2/10\n - 3s - loss: 2.8353 - MAE: 1.2928 - val_loss: 3.0619 - val_MAE: 1.3439\nEpoch 3/10\n - 3s - loss: 2.7199 - MAE: 1.2628 - val_loss: 3.0564 - val_MAE: 1.3349\nEpoch 4/10\n - 3s - loss: 2.6495 - MAE: 1.2429 - val_loss: 3.0513 - val_MAE: 1.3389\n"
    }
   ],
   "source": [
    "trained_model_add_enc= model_add.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 3.7466 - MAE: 1.4967 - val_loss: 3.0887 - val_MAE: 1.3615\nEpoch 2/10\n - 3s - loss: 2.8346 - MAE: 1.2934 - val_loss: 3.0448 - val_MAE: 1.3471\nEpoch 3/10\n - 3s - loss: 2.7029 - MAE: 1.2570 - val_loss: 3.0510 - val_MAE: 1.3465\nEpoch 4/10\n - 3s - loss: 2.6026 - MAE: 1.2292 - val_loss: 3.0385 - val_MAE: 1.3368\nEpoch 5/10\n - 3s - loss: 2.4852 - MAE: 1.1970 - val_loss: 3.0578 - val_MAE: 1.3298\nEpoch 6/10\n - 4s - loss: 2.3384 - MAE: 1.1562 - val_loss: 3.0739 - val_MAE: 1.3417\n"
    }
   ],
   "source": [
    "trained_model_substract_enc= model_substract.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 3s - loss: 4.4342 - MAE: 1.6637 - val_loss: 3.6382 - val_MAE: 1.4878\nEpoch 2/10\n - 3s - loss: 2.5127 - MAE: 1.2126 - val_loss: 3.5459 - val_MAE: 1.4560\nEpoch 3/10\n - 3s - loss: 1.2740 - MAE: 0.8484 - val_loss: 3.6570 - val_MAE: 1.4843\n"
    }
   ],
   "source": [
    "trained_model_multiply_enc= model_multiply.fit(x=[X_train_enc.user_id, X_train_enc.movie_id], y=y_train_enc, batch_size=500,epochs=10, verbose=2, validation_data=[[X_test_enc.user_id, X_test_enc.movie_id],y_test_enc], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUCH WORSE MAE!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}