{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitkagglenewpipenv345dfe1713484c20b6863d1100cfe670",
   "display_name": "Python 3.6.9 64-bit ('kaggle_new': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  loading data\n",
    "csv_ratings='ml-latest-small/ratings.csv'\n",
    "csv_movies='ml-latest-small/movies.csv'\n",
    "def get_data(csv_ratings,csv_movies):\n",
    "    zf = zipfile.ZipFile('/home/elena/Downloads/ml-latest-small.zip')\n",
    "    # reading ratings file:\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv(zf.open(csv_ratings), names=r_cols)\n",
    "    m_cols=['movie_id', 'title', 'genre']\n",
    "    movies = pd.read_csv(zf.open(csv_movies), names=m_cols)\n",
    "    # merging ratings and movies\n",
    "    ratings=pd.merge(ratings,movies,on='movie_id')\n",
    "    zz = zipfile.ZipFile('/home/elena/Downloads/ml-100k.zip')\n",
    "    # reading users file:\n",
    "    u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "    users = pd.read_csv(zz.open('ml-100k/u.user'), sep='|', names=u_cols,encoding='latin-1')\n",
    "    return pd.merge(users,ratings, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_data(csv_ratings,csv_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error I did before was to split the data in train & test randomly, but since the data is timestamped, I should use the first e.g. 80% for training, and the last 20% for testing! \n",
    "# To do so, I need to sort the data via unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(data):\n",
    "    data=data.sort_values(by=['unix_timestamp'], ascending=True)\n",
    "    data=data.reset_index(drop=True)\n",
    "    split=int(data.shape[0]*0.75)\n",
    "    train=data.iloc[0:split]\n",
    "    test=data.iloc[split:data.shape[0]]\n",
    "    return (data,train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, train, test=train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I indexed, and encoded cat features, BEFORE splitting, because I don't know how to handle new unseen index / encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing(data,train,test):\n",
    "    unique_movies = data.movie_id.unique() # returns a np array\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)} # indexing movie_id, tart at 0\n",
    "    index_to_movie = {idx: movie for movie, idx in movie_to_index.items()}\n",
    "    new_movies = data.movie_id.map(movie_to_index) # replaces movie_id with coresp. index\n",
    "    data['movie_index']=new_movies\n",
    "    train['movie_index']=train.movie_id.map(movie_to_index)\n",
    "    test['movie_index']=test.movie_id.map(movie_to_index)\n",
    "    return (data,train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, train, test=indexing(data,train,test)\n",
    "y_train=train['rating']\n",
    "y_test=test['rating']\n",
    "X_train=train.drop('rating', axis=1)\n",
    "X_test=test.drop('rating', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation \n",
    "from keras.layers import Input, Embedding, Concatenate, Flatten, Dense, Dot, Add, Multiply, Subtract, Average, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method):\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    # Embeddings\n",
    "    user_embedded = Embedding(user_max_cat_value+1, user_embedding_dim, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "    movie_embedded = Embedding(movie_max_cat_value+1, movie_embedding_dim, \n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "    # merging the embeddings\n",
    "    if merging_method=='concatenate':\n",
    "        merged = Concatenate()([user_embedded, movie_embedded])\n",
    "    if merging_method=='dot_product':\n",
    "        merged =Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedded, movie_embedded])\n",
    "    if merging_method=='add':\n",
    "        merged =Add()([user_embedded, movie_embedded])\n",
    "    if merging_method=='substract':\n",
    "        merged=Subtract()([user_embedded, movie_embedded])\n",
    "    if merging_method=='multiply':\n",
    "        merged=Multiply()([user_embedded, movie_embedded])\n",
    "    if merging_method=='average':\n",
    "        merged=Average()([user_embedded, movie_embedded])\n",
    "    out = Flatten()(merged)\n",
    "\n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "        out = Dense(n_hidden, activation='relu')(out)\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = Dense(1, activation='linear', name='prediction')(out)\n",
    "    model = Model(inputs = [user_id_input, movie_id_input],outputs = out)\n",
    "    model.compile(optimizer = 'Adam',loss='MSE',metrics=['MAE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the models used\n",
    "hidden_units = (100,50) #same as in pytorch model\n",
    "movie_embedding_dim = 50 #same as in pytorch model\n",
    "user_embedding_dim = 50  #same as in pytorch model\n",
    "user_max_cat_value = data.user_id.max()\n",
    "movie_max_cat_value=max(train.movie_index.max(), test.movie_index.max())\n",
    "es=EarlyStopping(monitor='val_MAE', min_delta=0, patience=0, verbose=0, mode='min', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergemethod=['concatenate','dot_product','add','substract', 'multiply','average']\n",
    "summary=pd.DataFrame(columns=['merge','val_MAE', 'MAE','epoch','val_loss', 'loss'])\n",
    "merge,epoch,val_MAE,MAE,loss,val_loss=[],[],[],[],[],[]\n",
    "# for prediction\n",
    "uid=1\n",
    "movies_test=X_test.movie_index[X_test.user_id==uid]\n",
    "predictions=pd.DataFrame(movies_test.values)\n",
    "predictions.columns=['movie_index']\n",
    "# looping through the merging methods\n",
    "for m in mergemethod:\n",
    "    model=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method=m)\n",
    "    history=model.fit(x=[X_train.user_id, X_train.movie_index], y=y_train, batch_size=500,epochs=10, verbose=0, validation_data=[[X_test.user_id, X_test.movie_index],y_test], callbacks=[es])\n",
    "    # predicting for user uid\n",
    "    pred=model.predict([[uid]*len(movies_test),movies_test.index])\n",
    "    predictions[m]=pred\n",
    "    # collecting MAE's and loss\n",
    "    merge.append(m)\n",
    "    n=len(history.epoch)\n",
    "    epoch.append(n)\n",
    "    val_MAE.append(history.history['val_MAE'][n-1])\n",
    "    MAE.append(history.history['MAE'][n-1])\n",
    "    loss.append(history.history['loss'][n-1])\n",
    "    val_loss.append(history.history['val_loss'][n-1])\n",
    "summary['merge']=merge \n",
    "summary['val_MAE']=val_MAE \n",
    "summary['epoch']=epoch\n",
    "summary['MAE']=MAE \n",
    "summary['loss']=loss \n",
    "summary['val_loss']=val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge   val_MAE       MAE  epoch  val_loss      loss\n0  concatenate  1.037041  0.578878     10  1.585603  0.582871\n1  dot_product  0.861144  0.816102      2  1.170489  1.043170\n2          add  1.190237  0.599088      8  1.971669  0.619108\n3    substract  1.120649  0.613489      6  1.783306  0.644329\n4     multiply  0.896178  0.733016      2  1.198117  0.873399\n5      average  1.155865  0.625325      8  1.872036  0.667989",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE</th>\n      <th>MAE</th>\n      <th>epoch</th>\n      <th>val_loss</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>1.037041</td>\n      <td>0.578878</td>\n      <td>10</td>\n      <td>1.585603</td>\n      <td>0.582871</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.861144</td>\n      <td>0.816102</td>\n      <td>2</td>\n      <td>1.170489</td>\n      <td>1.043170</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>1.190237</td>\n      <td>0.599088</td>\n      <td>8</td>\n      <td>1.971669</td>\n      <td>0.619108</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>1.120649</td>\n      <td>0.613489</td>\n      <td>6</td>\n      <td>1.783306</td>\n      <td>0.644329</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.896178</td>\n      <td>0.733016</td>\n      <td>2</td>\n      <td>1.198117</td>\n      <td>0.873399</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>1.155865</td>\n      <td>0.625325</td>\n      <td>8</td>\n      <td>1.872036</td>\n      <td>0.667989</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergemethod=['concatenate','dot_product','add','substract', 'multiply','average']\n",
    "summary=pd.DataFrame(columns=['merge','val_MAE', 'MAE','epoch','val_loss', 'loss'])\n",
    "merge,epoch,val_MAE,MAE,loss,val_loss=[],[],[],[],[],[]\n",
    "# for prediction\n",
    "uid=1\n",
    "movies_test=X_test.movie_index[X_test.user_id==uid]\n",
    "predictions=pd.DataFrame(movies_test.values)\n",
    "predictions.columns=['movie_index']\n",
    "# looping through the merging methods\n",
    "for m in mergemethod:\n",
    "    model=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method=m)\n",
    "    history=model.fit(x=[data.user_id, data.movie_index], y=data.rating, batch_size=500,epochs=10, verbose=0, validation_split=0.25, callbacks=[es])\n",
    "    # predicting for user uid\n",
    "    pred=model.predict([[uid]*len(movies_test),movies_test.index])\n",
    "    predictions[m]=pred\n",
    "    # collecting MAE's and loss\n",
    "    merge.append(m)\n",
    "    n=len(history.epoch)\n",
    "    epoch.append(n)\n",
    "    val_MAE.append(history.history['val_MAE'][n-1])\n",
    "    MAE.append(history.history['MAE'][n-1])\n",
    "    loss.append(history.history['loss'][n-1])\n",
    "    val_loss.append(history.history['val_loss'][n-1])\n",
    "summary['merge']=merge \n",
    "summary['val_MAE']=val_MAE \n",
    "summary['epoch']=epoch\n",
    "summary['MAE']=MAE \n",
    "summary['loss']=loss \n",
    "summary['val_loss']=val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge   val_MAE       MAE  epoch  val_loss      loss\n0  concatenate  1.075500  0.556109     10  1.673567  0.540143\n1  dot_product  0.863385  0.810375      2  1.165890  1.036259\n2          add  1.167191  0.566769      8  1.948975  0.560297\n3    substract  1.195468  0.569310      9  2.022678  0.566003\n4     multiply  0.905970  0.722775      2  1.216452  0.854723\n5      average  0.985534  0.611320     10  1.433625  0.643704",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE</th>\n      <th>MAE</th>\n      <th>epoch</th>\n      <th>val_loss</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>1.075500</td>\n      <td>0.556109</td>\n      <td>10</td>\n      <td>1.673567</td>\n      <td>0.540143</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.863385</td>\n      <td>0.810375</td>\n      <td>2</td>\n      <td>1.165890</td>\n      <td>1.036259</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>1.167191</td>\n      <td>0.566769</td>\n      <td>8</td>\n      <td>1.948975</td>\n      <td>0.560297</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>1.195468</td>\n      <td>0.569310</td>\n      <td>9</td>\n      <td>2.022678</td>\n      <td>0.566003</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.905970</td>\n      <td>0.722775</td>\n      <td>2</td>\n      <td>1.216452</td>\n      <td>0.854723</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.985534</td>\n      <td>0.611320</td>\n      <td>10</td>\n      <td>1.433625</td>\n      <td>0.643704</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# much worse then before! dot product and multiply turned out to be the 'best'\n",
    "# lets try a LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddingLSTM_model(hidden_units,user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method):\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    # Embeddings\n",
    "    user_embedded = Embedding(user_max_cat_value+1, user_embedding_dim, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "    movie_embedded = Embedding(movie_max_cat_value+1, movie_embedding_dim, \n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "    # merging the embeddings\n",
    "    if merging_method=='concatenate':\n",
    "        merged = Concatenate()([user_embedded, movie_embedded])\n",
    "    if merging_method=='dot_product':\n",
    "        merged =Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedded, movie_embedded])\n",
    "    if merging_method=='add':\n",
    "        merged =Add()([user_embedded, movie_embedded])\n",
    "    if merging_method=='substract':\n",
    "        merged=Subtract()([user_embedded, movie_embedded])\n",
    "    if merging_method=='multiply':\n",
    "        merged=Multiply()([user_embedded, movie_embedded])\n",
    "    if merging_method=='average':\n",
    "        merged=Average()([user_embedded, movie_embedded])\n",
    "    #out = Flatten()(merged)\n",
    "\n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "        out = LSTM(n_hidden, activation='relu')(merged)# LSTM instead of Dense\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = Dense(1, activation='linear', name='prediction')(out)\n",
    "    model = Model(inputs = [user_id_input, movie_id_input],outputs = out)\n",
    "    model.compile(optimizer = 'Adam',loss='MSE',metrics=['MAE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergemethod=['concatenate','dot_product','add','substract', 'multiply','average']\n",
    "summary=pd.DataFrame(columns=['merge','val_MAE', 'MAE','epoch','val_loss', 'loss'])\n",
    "merge,epoch,val_MAE,MAE,loss,val_loss=[],[],[],[],[],[]\n",
    "# for prediction\n",
    "uid=1\n",
    "movies_test=X_test.movie_index[X_test.user_id==uid]\n",
    "predictions=pd.DataFrame(movies_test.values)\n",
    "predictions.columns=['movie_index']\n",
    "# looping through the merging methods\n",
    "for m in mergemethod:\n",
    "    model=embeddingLSTM_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method=m)\n",
    "    history=model.fit(x=[data.user_id, data.movie_index], y=data.rating, batch_size=500,epochs=10, verbose=0, validation_split=0.75, callbacks=[es])\n",
    "    # predicting for user uid\n",
    "    pred=model.predict([[uid]*len(movies_test),movies_test.index])\n",
    "    predictions[m]=pred\n",
    "    # collecting MAE's and loss\n",
    "    merge.append(m)\n",
    "    n=len(history.epoch)\n",
    "    epoch.append(n)\n",
    "    val_MAE.append(history.history['val_MAE'][n-1])\n",
    "    MAE.append(history.history['MAE'][n-1])\n",
    "    loss.append(history.history['loss'][n-1])\n",
    "    val_loss.append(history.history['val_loss'][n-1])\n",
    "summary['merge']=merge \n",
    "summary['val_MAE']=val_MAE \n",
    "summary['epoch']=epoch\n",
    "summary['MAE']=MAE \n",
    "summary['loss']=loss \n",
    "summary['val_loss']=val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge   val_MAE       MAE  epoch  val_loss      loss\n0  concatenate  2.696847  0.767699      3  8.523975  0.948813\n1  dot_product  1.757958  0.436966     10  3.928167  0.338548\n2          add  2.678453  0.763909      3  8.417517  0.937233\n3    substract  2.605697  0.658283     10  8.061807  0.708656\n4     multiply  2.190618  0.557637     10  5.717753  0.524398\n5      average  2.527856  0.657762     10  7.621267  0.705806",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE</th>\n      <th>MAE</th>\n      <th>epoch</th>\n      <th>val_loss</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>2.696847</td>\n      <td>0.767699</td>\n      <td>3</td>\n      <td>8.523975</td>\n      <td>0.948813</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>1.757958</td>\n      <td>0.436966</td>\n      <td>10</td>\n      <td>3.928167</td>\n      <td>0.338548</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>2.678453</td>\n      <td>0.763909</td>\n      <td>3</td>\n      <td>8.417517</td>\n      <td>0.937233</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>2.605697</td>\n      <td>0.658283</td>\n      <td>10</td>\n      <td>8.061807</td>\n      <td>0.708656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>2.190618</td>\n      <td>0.557637</td>\n      <td>10</td>\n      <td>5.717753</td>\n      <td>0.524398</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>2.527856</td>\n      <td>0.657762</td>\n      <td>10</td>\n      <td>7.621267</td>\n      <td>0.705806</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# much much much worse!!"
   ]
  }
 ]
}