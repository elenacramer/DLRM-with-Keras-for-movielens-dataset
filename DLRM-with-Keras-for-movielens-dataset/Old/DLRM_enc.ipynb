{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitkagglenewpipenv345dfe1713484c20b6863d1100cfe670",
   "display_name": "Python 3.6.9 64-bit ('kaggle_new': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  loading data\n",
    "csv_ratings='ml-latest-small/ratings.csv'\n",
    "csv_movies='ml-latest-small/movies.csv'\n",
    "def get_data_ratings(csv_ratings,csv_movies):\n",
    "    zf = zipfile.ZipFile('/home/elena/Downloads/ml-latest-small.zip')\n",
    "    # reading ratings file:\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv(zf.open(csv_ratings), names=r_cols)\n",
    "    m_cols=['movie_id', 'title', 'genre']\n",
    "    movies = pd.read_csv(zf.open(csv_movies), names=m_cols)\n",
    "    # merging ratings and movies\n",
    "    # ratings=pd.merge(ratings,movies,on='movie_id')\n",
    "    return pd.merge(ratings,movies,on='movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=get_data_ratings(csv_ratings,csv_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train / test data\n",
    "def train_test_data(ratings):\n",
    "    unique_movies = ratings.movie_id.unique() # returns a np array\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)} # indexing movie_id, tart at 0\n",
    "    index_to_movie = {idx: movie for movie, idx in movie_to_index.items()}\n",
    "    new_movies = ratings.movie_id.map(movie_to_index) # replaces movie_id with coresp. index\n",
    "    ratings['movie_index']=new_movies\n",
    "\n",
    "    train=pd.read_pickle('/home/elena/Downloads/traindata.pkl')\n",
    "    test=pd.read_pickle('/home/elena/Downloads/testdata.pkl')\n",
    "    train['movie_index']=train.movie_id.map(movie_to_index)\n",
    "    test['movie_index']=test.movie_id.map(movie_to_index)\n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train.rating\n",
    "y_test=test.rating\n",
    "X_train=train.drop('rating', axis=1)\n",
    "X_test=test.drop('rating', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Implementation \n",
    "from keras.layers import Input, Embedding, Concatenate, Flatten, Dense, Dot, Add, Multiply, Subtract, Average, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method, recurrent):\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    # Embeddings\n",
    "    user_embedded = Embedding(user_max_cat_value+1, user_embedding_dim, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "    movie_embedded = Embedding(movie_max_cat_value+1, movie_embedding_dim, \n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "    # merging the embeddings\n",
    "    if merging_method=='concatenate':\n",
    "        merged = Concatenate()([user_embedded, movie_embedded])\n",
    "    if merging_method=='dot_product':\n",
    "        merged =Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedded, movie_embedded])\n",
    "    if merging_method=='add':\n",
    "        merged =Add()([user_embedded, movie_embedded])\n",
    "    if merging_method=='substract':\n",
    "        merged=Subtract()([user_embedded, movie_embedded])\n",
    "    if merging_method=='multiply':\n",
    "        merged=Multiply()([user_embedded, movie_embedded])\n",
    "    if merging_method=='average':\n",
    "        merged=Average()([user_embedded, movie_embedded])\n",
    "    if recurrent == None:\n",
    "        out = Flatten()(merged)\n",
    "        for n_hidden in hidden_units:\n",
    "            out = Dense(n_hidden, activation='relu')(out)\n",
    "    else: \n",
    "        for n_hidden in hidden_units:\n",
    "            out = LSTM(n_hidden, activation='relu')(merged)\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = Dense(1, activation='linear', name='prediction')(out)\n",
    "    model = Model(inputs = [user_id_input, movie_id_input],outputs = out)\n",
    "    model.compile(optimizer = 'Adam',loss='MSE',metrics=['MAE'])\n",
    "    return model\n",
    "\n",
    "# fitting models and predicting\n",
    "def result(uid, mergemethod, X_train, X_test, y_train, y_test, rec):\n",
    "    summary=pd.DataFrame(columns=['merge','val_MAE', 'MAE','epoch','val_loss', 'loss'])\n",
    "    merge,epoch,val_MAE,MAE,loss,val_loss=[],[],[],[],[],[]\n",
    "    # for prediction\n",
    "    movies_test=X_test.movie_index[X_test.user_id==uid]\n",
    "    predictions=pd.DataFrame(movies_test.values)\n",
    "    predictions.columns=['movie_index']\n",
    "    # looping through the merging methods\n",
    "    for m in mergemethod:\n",
    "        model=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method=m, recurrent=rec)\n",
    "        history=model.fit(x=[X_train.user_id, X_train.movie_index], y=y_train, batch_size=500,epochs=10, verbose=0, validation_data=[[X_test.user_id, X_test.movie_index],y_test], callbacks=[es])\n",
    "        # predicting for user uid\n",
    "        pred=model.predict([[uid]*len(movies_test),movies_test.index])\n",
    "        predictions[m]=pred\n",
    "        # collecting MAE's and loss\n",
    "        merge.append(m)\n",
    "        n=len(history.epoch)\n",
    "        epoch.append(n)\n",
    "        val_MAE.append(history.history['val_MAE'][n-1])\n",
    "        MAE.append(history.history['MAE'][n-1])\n",
    "        loss.append(history.history['loss'][n-1])\n",
    "        val_loss.append(history.history['val_loss'][n-1])\n",
    "    summary['merge']=merge \n",
    "    summary['val_MAE']=val_MAE \n",
    "    summary['epoch']=epoch\n",
    "    summary['MAE']=MAE \n",
    "    summary['loss']=loss \n",
    "    summary['val_loss']=val_loss\n",
    "    top_5=pd.DataFrame()\n",
    "    for n in mergemethod:\n",
    "        top_5[n]=predictions.nlargest(5,n).movie_index.values\n",
    "    return (summary, top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the models used\n",
    "hidden_units = (100,50) #same as in pytorch model\n",
    "movie_embedding_dim = 50 #same as in pytorch model\n",
    "user_embedding_dim = 50  #same as in pytorch model\n",
    "user_max_cat_value = ratings.user_id.max()\n",
    "movie_max_cat_value=max(X_train.movie_index.max(), X_test.movie_index.max())\n",
    "es=EarlyStopping(monitor='val_MAE', min_delta=0, patience=0, verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
    "# for fitting and predicting\n",
    "mergemethod=['concatenate','dot_product','add','substract', 'multiply','average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary1, prediction1=result(1,mergemethod, X_train, X_test, y_train, y_test, rec= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge   val_MAE       MAE  epoch  val_loss      loss\n0  concatenate  0.666741  0.586439      9  0.758934  0.600377\n1  dot_product  0.839333  0.819236      2  1.091499  1.053186\n2          add  0.683493  0.626266      4  0.779204  0.671930\n3    substract  0.683770  0.637900      3  0.779475  0.693045\n4     multiply  0.741740  0.520810      3  0.906672  0.470945\n5      average  0.673603  0.627302      4  0.769251  0.674279",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE</th>\n      <th>MAE</th>\n      <th>epoch</th>\n      <th>val_loss</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>0.666741</td>\n      <td>0.586439</td>\n      <td>9</td>\n      <td>0.758934</td>\n      <td>0.600377</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.839333</td>\n      <td>0.819236</td>\n      <td>2</td>\n      <td>1.091499</td>\n      <td>1.053186</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>0.683493</td>\n      <td>0.626266</td>\n      <td>4</td>\n      <td>0.779204</td>\n      <td>0.671930</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>0.683770</td>\n      <td>0.637900</td>\n      <td>3</td>\n      <td>0.779475</td>\n      <td>0.693045</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.741740</td>\n      <td>0.520810</td>\n      <td>3</td>\n      <td>0.906672</td>\n      <td>0.470945</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.673603</td>\n      <td>0.627302</td>\n      <td>4</td>\n      <td>0.769251</td>\n      <td>0.674279</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge   val_MAE       MAE  epoch  val_loss      loss\n0  concatenate  0.663808  0.587815      9  0.762902  0.602770\n1  dot_product  0.837408  0.819400      2  1.091396  1.055124\n2          add  0.678036  0.637935      3  0.775935  0.692228\n3    substract  0.675556  0.619166      5  0.767822  0.659461\n4     multiply  0.735127  0.525711      3  0.895239  0.478696\n5      average  0.673198  0.636541      3  0.767651  0.690644",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE</th>\n      <th>MAE</th>\n      <th>epoch</th>\n      <th>val_loss</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>0.663808</td>\n      <td>0.587815</td>\n      <td>9</td>\n      <td>0.762902</td>\n      <td>0.602770</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.837408</td>\n      <td>0.819400</td>\n      <td>2</td>\n      <td>1.091396</td>\n      <td>1.055124</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>0.678036</td>\n      <td>0.637935</td>\n      <td>3</td>\n      <td>0.775935</td>\n      <td>0.692228</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>0.675556</td>\n      <td>0.619166</td>\n      <td>5</td>\n      <td>0.767822</td>\n      <td>0.659461</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.735127</td>\n      <td>0.525711</td>\n      <td>3</td>\n      <td>0.895239</td>\n      <td>0.478696</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.673198</td>\n      <td>0.636541</td>\n      <td>3</td>\n      <td>0.767651</td>\n      <td>0.690644</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "# summary first run - best models are concat and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   concatenate  dot_product  add  substract  multiply  average\n0           70          147  147        147       164       70\n1          114          164   70        114        53      147\n2          147          127  179        226       127      222\n3          226           35  219        222       103      219\n4          222          161  114         70        87      103",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>concatenate</th>\n      <th>dot_product</th>\n      <th>add</th>\n      <th>substract</th>\n      <th>multiply</th>\n      <th>average</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70</td>\n      <td>147</td>\n      <td>147</td>\n      <td>147</td>\n      <td>164</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114</td>\n      <td>164</td>\n      <td>70</td>\n      <td>114</td>\n      <td>53</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>147</td>\n      <td>127</td>\n      <td>179</td>\n      <td>226</td>\n      <td>127</td>\n      <td>222</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>226</td>\n      <td>35</td>\n      <td>219</td>\n      <td>222</td>\n      <td>103</td>\n      <td>219</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>222</td>\n      <td>161</td>\n      <td>114</td>\n      <td>70</td>\n      <td>87</td>\n      <td>103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we repeat the above steps but prepare the data for the model by using an Integer Encoding (from kaggle) instead of indexing the movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# loading train / test data\n",
    "def train_test_data_enc(ratings):\n",
    "    train=pd.read_pickle('/home/elena/Downloads/traindata.pkl')\n",
    "    test=pd.read_pickle('/home/elena/Downloads/testdata.pkl')\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(ratings['movie_id'])\n",
    "    train['movie_index'] = label_encoder.transform(train['movie_id']) # calling it index to use the function above!\n",
    "    test['movie_index'] = label_encoder.transform(test['movie_id'])\n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc, test_enc=train_test_data_enc(ratings)\n",
    "y_train_enc=train_enc.rating\n",
    "y_test_enc=test_enc.rating\n",
    "X_train_enc=train_enc.drop('rating',axis=1)\n",
    "X_test_enc=test_enc.drop('rating',axis=1)\n",
    "movie_max_cat_value_enc=max(X_train_enc.movie_index.max(), X_test_enc.movie_index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_enc, prediction_enc=result(1,mergemethod, X_train_enc, X_test_enc, y_train_enc, y_test_enc,rec= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge  val_MAE_x     MAE_x  val_MAE_y     MAE_y\n0  concatenate   0.666741  0.586439   0.675895  0.627993\n1  dot_product   0.839333  0.819236   0.834470  0.825090\n2          add   0.683493  0.626266   0.674154  0.626612\n3    substract   0.683770  0.637900   0.678025  0.626050\n4     multiply   0.741740  0.520810   0.745583  0.524609\n5      average   0.673603  0.627302   0.678869  0.635407",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE_x</th>\n      <th>MAE_x</th>\n      <th>val_MAE_y</th>\n      <th>MAE_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>0.666741</td>\n      <td>0.586439</td>\n      <td>0.675895</td>\n      <td>0.627993</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.839333</td>\n      <td>0.819236</td>\n      <td>0.834470</td>\n      <td>0.825090</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>0.683493</td>\n      <td>0.626266</td>\n      <td>0.674154</td>\n      <td>0.626612</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>0.683770</td>\n      <td>0.637900</td>\n      <td>0.678025</td>\n      <td>0.626050</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.741740</td>\n      <td>0.520810</td>\n      <td>0.745583</td>\n      <td>0.524609</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.673603</td>\n      <td>0.627302</td>\n      <td>0.678869</td>\n      <td>0.635407</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "pd.merge(summary1[['merge','val_MAE','MAE']],summary_enc[['merge','val_MAE','MAE']],on='merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now use a recurrent neural network -> LSTM\n",
    "# we will use the data with movie_index since we got a little better result there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lstm, prediction_lstm=result(1,mergemethod, X_train, X_test, y_train, y_test, rec= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge  val_MAE_x     MAE_x  val_MAE_y     MAE_y\n0  concatenate   0.685221  0.636862   0.686137  0.637342\n1  dot_product   0.713182  0.381853   0.721797  0.416107\n2          add   0.696987  0.625092   0.699230  0.627272\n3    substract   0.697403  0.640078   0.695633  0.632508\n4     multiply   0.753478  0.510704   0.738477  0.533977\n5      average   0.689902  0.623564   0.689554  0.629755",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE_x</th>\n      <th>MAE_x</th>\n      <th>val_MAE_y</th>\n      <th>MAE_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>0.685221</td>\n      <td>0.636862</td>\n      <td>0.686137</td>\n      <td>0.637342</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.713182</td>\n      <td>0.381853</td>\n      <td>0.721797</td>\n      <td>0.416107</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>0.696987</td>\n      <td>0.625092</td>\n      <td>0.699230</td>\n      <td>0.627272</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>0.697403</td>\n      <td>0.640078</td>\n      <td>0.695633</td>\n      <td>0.632508</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.753478</td>\n      <td>0.510704</td>\n      <td>0.738477</td>\n      <td>0.533977</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.689902</td>\n      <td>0.623564</td>\n      <td>0.689554</td>\n      <td>0.629755</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "pd.merge(summary1[['merge','val_MAE','MAE']],summary_lstm[['merge','val_MAE','MAE']],on='merge')\n",
    "# almost the same MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   concatenate  dot_product  add  substract  multiply  average\n0           70           70  147        147        70       70\n1          147          115  114        114       226      147\n2           75          147  222        222       222      114\n3          114          219   70         70       127      103\n4           87          114   75        226        75      164",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>concatenate</th>\n      <th>dot_product</th>\n      <th>add</th>\n      <th>substract</th>\n      <th>multiply</th>\n      <th>average</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70</td>\n      <td>70</td>\n      <td>147</td>\n      <td>147</td>\n      <td>70</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>147</td>\n      <td>115</td>\n      <td>114</td>\n      <td>114</td>\n      <td>226</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75</td>\n      <td>147</td>\n      <td>222</td>\n      <td>222</td>\n      <td>222</td>\n      <td>114</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>114</td>\n      <td>219</td>\n      <td>70</td>\n      <td>70</td>\n      <td>127</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>87</td>\n      <td>114</td>\n      <td>75</td>\n      <td>226</td>\n      <td>75</td>\n      <td>164</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "prediction_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now predict movies and time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_data(ratings)\n",
    "y_train=train[['rating','unix_timestamp']]\n",
    "y_test=test[['rating','unix_timestamp']]\n",
    "X_train=train.drop(['rating','unix_timestamp'], axis=1)\n",
    "X_test=test.drop(['rating','unix_timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing unix_timestamp\n",
    "max_train=y_train.unix_timestamp.max()\n",
    "y_train['norm']=[float(i)/max_train for i in y_train.unix_timestamp]\n",
    "max_test=y_test.unix_timestamp.max()\n",
    "y_test['norm']=[float(i)/max_test for i in y_test.unix_timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1.0, 0.5385275978108841, 1.0, 0.5385128227888003)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "y_train.norm.max(),y_train.norm.min(), y_test.norm.max(),y_test.norm.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the models used\n",
    "hidden_units = (100,50) #same as in pytorch model\n",
    "movie_embedding_dim = 50 #same as in pytorch model\n",
    "user_embedding_dim = 50  #same as in pytorch model\n",
    "user_max_cat_value = ratings.user_id.max()\n",
    "movie_max_cat_value=X_test.movie_index.max()\n",
    "es=EarlyStopping(monitor='val_MAE', min_delta=0, patience=0, verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
    "# the model \n",
    "#\n",
    "#\n",
    "def embedding_model_mult_out(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method, recurrent):\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    # Embeddings\n",
    "    user_embedded = Embedding(user_max_cat_value+1, user_embedding_dim, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "    movie_embedded = Embedding(movie_max_cat_value+1, movie_embedding_dim, \n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "    # merging the embeddings\n",
    "    if merging_method=='concatenate':\n",
    "        merged = Concatenate()([user_embedded, movie_embedded])\n",
    "    if merging_method=='dot_product':\n",
    "        merged =Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedded, movie_embedded])\n",
    "    if merging_method=='add':\n",
    "        merged =Add()([user_embedded, movie_embedded])\n",
    "    if merging_method=='substract':\n",
    "        merged=Subtract()([user_embedded, movie_embedded])\n",
    "    if merging_method=='multiply':\n",
    "        merged=Multiply()([user_embedded, movie_embedded])\n",
    "    if merging_method=='average':\n",
    "        merged=Average()([user_embedded, movie_embedded])\n",
    "    if recurrent == None:\n",
    "        out = Flatten()(merged)\n",
    "        for n_hidden in hidden_units:\n",
    "            out = Dense(n_hidden, activation='relu')(out)\n",
    "    else: \n",
    "        for n_hidden in hidden_units:\n",
    "            out = LSTM(n_hidden, activation='relu')(merged)\n",
    "\n",
    "    #Two outputs: our predicted rating and unix_timestamp\n",
    "    out_movie = Dense(1, activation='linear', name='movies_pred')(out)\n",
    "    out_time = Dense(1, activation='relu', name='time_pred')(out)\n",
    "    model = Model(inputs = [user_id_input, movie_id_input],outputs = [out_movie, out_time])\n",
    "    model.compile(optimizer = 'Adam',loss='MSE',metrics=['MAE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 5s - loss: 3.6784 - movies_pred_loss: 3.5300 - time_pred_loss: 0.1351 - movies_pred_MAE: 1.3891 - time_pred_MAE: 0.2786 - val_loss: 0.8145 - val_movies_pred_loss: 0.7855 - val_time_pred_loss: 0.0285 - val_movies_pred_MAE: 0.6836 - val_time_pred_MAE: 0.1354\nEpoch 2/10\n - 4s - loss: 0.7535 - movies_pred_loss: 0.7312 - time_pred_loss: 0.0229 - movies_pred_MAE: 0.6574 - time_pred_MAE: 0.1217 - val_loss: 0.7796 - val_movies_pred_loss: 0.7639 - val_time_pred_loss: 0.0149 - val_movies_pred_MAE: 0.6717 - val_time_pred_MAE: 0.0992\nEpoch 3/10\n - 4s - loss: 0.6983 - movies_pred_loss: 0.6898 - time_pred_loss: 0.0084 - movies_pred_MAE: 0.6363 - time_pred_MAE: 0.0716 - val_loss: 0.7699 - val_movies_pred_loss: 0.7645 - val_time_pred_loss: 0.0046 - val_movies_pred_MAE: 0.6707 - val_time_pred_MAE: 0.0518\nEpoch 4/10\n - 4s - loss: 0.6763 - movies_pred_loss: 0.6739 - time_pred_loss: 0.0032 - movies_pred_MAE: 0.6268 - time_pred_MAE: 0.0423 - val_loss: 0.7684 - val_movies_pred_loss: 0.7653 - val_time_pred_loss: 0.0024 - val_movies_pred_MAE: 0.6741 - val_time_pred_MAE: 0.0360\nEpoch 5/10\n - 4s - loss: 0.6653 - movies_pred_loss: 0.6642 - time_pred_loss: 0.0018 - movies_pred_MAE: 0.6208 - time_pred_MAE: 0.0311 - val_loss: 0.7689 - val_movies_pred_loss: 0.7666 - val_time_pred_loss: 0.0017 - val_movies_pred_MAE: 0.6706 - val_time_pred_MAE: 0.0287\nEpoch 6/10\n - 4s - loss: 0.6569 - movies_pred_loss: 0.6556 - time_pred_loss: 0.0013 - movies_pred_MAE: 0.6161 - time_pred_MAE: 0.0259 - val_loss: 0.7677 - val_movies_pred_loss: 0.7655 - val_time_pred_loss: 0.0014 - val_movies_pred_MAE: 0.6701 - val_time_pred_MAE: 0.0252\nEpoch 7/10\n - 4s - loss: 0.6493 - movies_pred_loss: 0.6479 - time_pred_loss: 0.0012 - movies_pred_MAE: 0.6112 - time_pred_MAE: 0.0243 - val_loss: 0.7692 - val_movies_pred_loss: 0.7669 - val_time_pred_loss: 0.0015 - val_movies_pred_MAE: 0.6670 - val_time_pred_MAE: 0.0268\nEpoch 8/10\n - 4s - loss: 0.6406 - movies_pred_loss: 0.6393 - time_pred_loss: 0.0013 - movies_pred_MAE: 0.6067 - time_pred_MAE: 0.0263 - val_loss: 0.7620 - val_movies_pred_loss: 0.7597 - val_time_pred_loss: 0.0016 - val_movies_pred_MAE: 0.6672 - val_time_pred_MAE: 0.0283\nEpoch 9/10\n - 4s - loss: 0.6276 - movies_pred_loss: 0.6271 - time_pred_loss: 0.0013 - movies_pred_MAE: 0.6000 - time_pred_MAE: 0.0263 - val_loss: 0.7574 - val_movies_pred_loss: 0.7554 - val_time_pred_loss: 0.0014 - val_movies_pred_MAE: 0.6677 - val_time_pred_MAE: 0.0248\nEpoch 10/10\n - 4s - loss: 0.6109 - movies_pred_loss: 0.6095 - time_pred_loss: 0.0012 - movies_pred_MAE: 0.5919 - time_pred_MAE: 0.0253 - val_loss: 0.7504 - val_movies_pred_loss: 0.7484 - val_time_pred_loss: 0.0015 - val_movies_pred_MAE: 0.6604 - val_time_pred_MAE: 0.0265\n"
    }
   ],
   "source": [
    "model=embedding_model_mult_out(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method='average', recurrent= None)\n",
    "history=model.fit(x=[X_train.user_id, X_train.movie_index], y=[y_train.rating,y_train.norm], batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_index],[y_test.rating,y_test.norm]], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.59185225, 0.6603676676750183, 0.025341213, 0.02654862217605114)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "history.history['movies_pred_MAE'][9], history.history['val_movies_pred_MAE'][9], history.history['time_pred_MAE'][9], history.history['val_time_pred_MAE'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid=1\n",
    "movies_test=X_test.movie_index[X_test.user_id==uid]\n",
    "predictions=pd.DataFrame(movies_test.values)\n",
    "predictions.columns=['movie_index']\n",
    "pred_movies=model.predict([[uid]*len(movies_test),movies_test.index]) # returns a list with 2 columns\n",
    "predictions['rating_pred']=pred_movies[0]\n",
    "predictions['time_pred']=pred_movies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   movie_index  rating_pred  time_pred\n0          226     4.426295   0.611767\n1          149     4.337087   0.619911\n2           87     4.556562   0.618144\n3           35     4.096316   0.607888\n4          134     4.401696   0.605820",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_index</th>\n      <th>rating_pred</th>\n      <th>time_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>226</td>\n      <td>4.426295</td>\n      <td>0.611767</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>149</td>\n      <td>4.337087</td>\n      <td>0.619911</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>87</td>\n      <td>4.556562</td>\n      <td>0.618144</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35</td>\n      <td>4.096316</td>\n      <td>0.607888</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>134</td>\n      <td>4.401696</td>\n      <td>0.605820</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   pred\n0    70\n1   147\n2   114\n3   219\n4    75",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>114</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>219</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "top_5=pd.DataFrame()\n",
    "top_5['pred']=predictions.nlargest(5,'rating_pred').movie_index.values\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 5s - loss: 7.7339 - movies_pred_loss: 7.4057 - time_pred_loss: 0.2959 - movies_pred_MAE: 2.3357 - time_pred_MAE: 0.4648 - val_loss: 1.1648 - val_movies_pred_loss: 1.1191 - val_time_pred_loss: 0.0446 - val_movies_pred_MAE: 0.8333 - val_time_pred_MAE: 0.1685\nEpoch 2/10\n - 4s - loss: 0.9250 - movies_pred_loss: 0.8883 - time_pred_loss: 0.0367 - movies_pred_MAE: 0.7327 - time_pred_MAE: 0.1538 - val_loss: 0.8749 - val_movies_pred_loss: 0.8390 - val_time_pred_loss: 0.0350 - val_movies_pred_MAE: 0.7079 - val_time_pred_MAE: 0.1496\nEpoch 3/10\n - 5s - loss: 0.7692 - movies_pred_loss: 0.7375 - time_pred_loss: 0.0326 - movies_pred_MAE: 0.6611 - time_pred_MAE: 0.1446 - val_loss: 0.8402 - val_movies_pred_loss: 0.8060 - val_time_pred_loss: 0.0334 - val_movies_pred_MAE: 0.6917 - val_time_pred_MAE: 0.1455\nEpoch 4/10\n - 4s - loss: 0.7270 - movies_pred_loss: 0.6962 - time_pred_loss: 0.0308 - movies_pred_MAE: 0.6404 - time_pred_MAE: 0.1403 - val_loss: 0.8355 - val_movies_pred_loss: 0.8031 - val_time_pred_loss: 0.0313 - val_movies_pred_MAE: 0.6892 - val_time_pred_MAE: 0.1414\nEpoch 5/10\n - 5s - loss: 0.7067 - movies_pred_loss: 0.6786 - time_pred_loss: 0.0284 - movies_pred_MAE: 0.6309 - time_pred_MAE: 0.1350 - val_loss: 0.8318 - val_movies_pred_loss: 0.8021 - val_time_pred_loss: 0.0289 - val_movies_pred_MAE: 0.6880 - val_time_pred_MAE: 0.1361\nEpoch 6/10\n - 5s - loss: 0.6903 - movies_pred_loss: 0.6683 - time_pred_loss: 0.0217 - movies_pred_MAE: 0.6245 - time_pred_MAE: 0.1174 - val_loss: 0.8199 - val_movies_pred_loss: 0.8051 - val_time_pred_loss: 0.0141 - val_movies_pred_MAE: 0.6891 - val_time_pred_MAE: 0.0938\nEpoch 7/10\n - 4s - loss: 0.6713 - movies_pred_loss: 0.6634 - time_pred_loss: 0.0077 - movies_pred_MAE: 0.6208 - time_pred_MAE: 0.0680 - val_loss: 0.8143 - val_movies_pred_loss: 0.8082 - val_time_pred_loss: 0.0054 - val_movies_pred_MAE: 0.6899 - val_time_pred_MAE: 0.0562\nEpoch 8/10\n - 5s - loss: 0.6632 - movies_pred_loss: 0.6601 - time_pred_loss: 0.0036 - movies_pred_MAE: 0.6179 - time_pred_MAE: 0.0455 - val_loss: 0.8157 - val_movies_pred_loss: 0.8114 - val_time_pred_loss: 0.0033 - val_movies_pred_MAE: 0.6895 - val_time_pred_MAE: 0.0424\nEpoch 9/10\n - 4s - loss: 0.6590 - movies_pred_loss: 0.6576 - time_pred_loss: 0.0023 - movies_pred_MAE: 0.6155 - time_pred_MAE: 0.0355 - val_loss: 0.8147 - val_movies_pred_loss: 0.8113 - val_time_pred_loss: 0.0023 - val_movies_pred_MAE: 0.6902 - val_time_pred_MAE: 0.0351\nEpoch 10/10\n - 4s - loss: 0.6567 - movies_pred_loss: 0.6544 - time_pred_loss: 0.0017 - movies_pred_MAE: 0.6147 - time_pred_MAE: 0.0295 - val_loss: 0.8134 - val_movies_pred_loss: 0.8107 - val_time_pred_loss: 0.0019 - val_movies_pred_MAE: 0.6897 - val_time_pred_MAE: 0.0301\n"
    }
   ],
   "source": [
    "# recurrent\n",
    "model=embedding_model_mult_out(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method='average', recurrent= 1)\n",
    "history=model.fit(x=[X_train.user_id, X_train.movie_index], y=[y_train.rating,y_train.norm], batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_index],[y_test.rating,y_test.norm]], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.61471206, 0.6896655559539795, 0.029456278, 0.03006492368876934)"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "history.history['movies_pred_MAE'][9], history.history['val_movies_pred_MAE'][9], history.history['time_pred_MAE'][9], history.history['val_time_pred_MAE'][9]\n",
    "# to compate without lstm \n",
    "# (0.59185225, 0.6603676676750183, 0.025341213, 0.02654862217605114)\n",
    "# without lstm better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}