{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitkagglenewpipenv345dfe1713484c20b6863d1100cfe670",
   "display_name": "Python 3.6.9 64-bit ('kaggle_new': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  loading data\n",
    "csv_ratings='ml-latest-small/ratings.csv'\n",
    "csv_movies='ml-latest-small/movies.csv'\n",
    "def get_data_ratings(csv_ratings,csv_movies):\n",
    "    zf = zipfile.ZipFile('/home/elena/Downloads/ml-latest-small.zip')\n",
    "    # reading ratings file:\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv(zf.open(csv_ratings), names=r_cols)\n",
    "    m_cols=['movie_id', 'title', 'genre']\n",
    "    movies = pd.read_csv(zf.open(csv_movies), names=m_cols)\n",
    "    # merging ratings and movies\n",
    "    # ratings=pd.merge(ratings,movies,on='movie_id')\n",
    "    return pd.merge(ratings,movies,on='movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=get_data_ratings(csv_ratings,csv_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train / test data\n",
    "def train_test_data(ratings):\n",
    "    unique_movies = ratings.movie_id.unique() # returns a np array\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)} # indexing movie_id, tart at 0\n",
    "    index_to_movie = {idx: movie for movie, idx in movie_to_index.items()}\n",
    "    new_movies = ratings.movie_id.map(movie_to_index) # replaces movie_id with coresp. index\n",
    "    ratings['movie_index']=new_movies\n",
    "\n",
    "    train=pd.read_pickle('/home/elena/Downloads/traindata.pkl')\n",
    "    test=pd.read_pickle('/home/elena/Downloads/testdata.pkl')\n",
    "    train['movie_index']=train.movie_id.map(movie_to_index)\n",
    "    test['movie_index']=test.movie_id.map(movie_to_index)\n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train.rating\n",
    "y_test=test.rating\n",
    "X_train=train.drop('rating', axis=1)\n",
    "X_test=test.drop('rating', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Implementation \n",
    "from keras.layers import Input, Embedding, Concatenate, Flatten, Dense, Dot, Add, Multiply, Subtract, Average\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method):\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    # Embeddings\n",
    "    user_embedded = Embedding(user_max_cat_value+1, user_embedding_dim, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "    movie_embedded = Embedding(movie_max_cat_value+1, movie_embedding_dim, \n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "    # merging the embeddings\n",
    "    if merging_method=='concatenate':\n",
    "        merged = Concatenate()([user_embedded, movie_embedded])\n",
    "    if merging_method=='dot_product':\n",
    "        merged =Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedded, movie_embedded])\n",
    "    if merging_method=='add':\n",
    "        merged =Add()([user_embedded, movie_embedded])\n",
    "    if merging_method=='substract':\n",
    "        merged=Subtract()([user_embedded, movie_embedded])\n",
    "    if merging_method=='multiply':\n",
    "        merged=Multiply()([user_embedded, movie_embedded])\n",
    "    if merging_method=='average':\n",
    "        merged=Average()([user_embedded, movie_embedded])\n",
    "    out = Flatten()(merged)\n",
    "\n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "        out = Dense(n_hidden, activation='relu')(out)\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = Dense(1, activation='linear', name='prediction')(out)\n",
    "    model = Model(inputs = [user_id_input, movie_id_input],outputs = out)\n",
    "    model.compile(optimizer = 'Adam',loss='MSE',metrics=['MAE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the models used\n",
    "hidden_units = (100,50) #same as in pytorch model\n",
    "movie_embedding_dim = 50 #same as in pytorch model\n",
    "user_embedding_dim = 50  #same as in pytorch model\n",
    "user_max_cat_value = ratings.user_id.max()\n",
    "movie_max_cat_value=max(X_train.movie_index.max(), X_test.movie_index.max())\n",
    "es=EarlyStopping(monitor='val_MAE', min_delta=0, patience=0, verbose=0, mode='min', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergemethod=['concatenate','dot_product','add','substract', 'multiply','average']\n",
    "summary=pd.DataFrame(columns=['merge','val_MAE', 'MAE','epoch','val_loss', 'loss'])\n",
    "merge,epoch,val_MAE,MAE,loss,val_loss=[],[],[],[],[],[]\n",
    "# for prediction\n",
    "uid=1\n",
    "movies_test=X_test.movie_index[X_test.user_id==uid]\n",
    "predictions=pd.DataFrame(movies_test.values)\n",
    "predictions.columns=['movie_index']\n",
    "# looping through the merging methods\n",
    "for m in mergemethod:\n",
    "    model=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method=m)\n",
    "    history=model.fit(x=[X_train.user_id, X_train.movie_index], y=y_train, batch_size=500,epochs=10, verbose=0, validation_data=[[X_test.user_id, X_test.movie_index],y_test], callbacks=[es])\n",
    "    # predicting for user uid\n",
    "    pred=model.predict([[uid]*len(movies_test),movies_test.index])\n",
    "    predictions[m]=pred\n",
    "    # collecting MAE's and loss\n",
    "    merge.append(m)\n",
    "    n=len(history.epoch)\n",
    "    epoch.append(n)\n",
    "    val_MAE.append(history.history['val_MAE'][n-1])\n",
    "    MAE.append(history.history['MAE'][n-1])\n",
    "    loss.append(history.history['loss'][n-1])\n",
    "    val_loss.append(history.history['val_loss'][n-1])\n",
    "summary['merge']=merge \n",
    "summary['val_MAE']=val_MAE \n",
    "summary['epoch']=epoch\n",
    "summary['MAE']=MAE \n",
    "summary['loss']=loss \n",
    "summary['val_loss']=val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge   val_MAE       MAE  epoch  val_loss      loss\n0  concatenate  0.675439  0.637787      3  0.772846  0.693698\n1  dot_product  0.787453  0.456959      4  1.012548  0.388622\n2          add  0.673487  0.613035      6  0.770759  0.650033\n3    substract  0.676568  0.627759      4  0.774539  0.675542\n4     multiply  0.726129  0.535156      3  0.872359  0.497630\n5      average  0.676141  0.635752      3  0.767803  0.689311",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE</th>\n      <th>MAE</th>\n      <th>epoch</th>\n      <th>val_loss</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>0.675439</td>\n      <td>0.637787</td>\n      <td>3</td>\n      <td>0.772846</td>\n      <td>0.693698</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.787453</td>\n      <td>0.456959</td>\n      <td>4</td>\n      <td>1.012548</td>\n      <td>0.388622</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>0.673487</td>\n      <td>0.613035</td>\n      <td>6</td>\n      <td>0.770759</td>\n      <td>0.650033</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>0.676568</td>\n      <td>0.627759</td>\n      <td>4</td>\n      <td>0.774539</td>\n      <td>0.675542</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.726129</td>\n      <td>0.535156</td>\n      <td>3</td>\n      <td>0.872359</td>\n      <td>0.497630</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.676141</td>\n      <td>0.635752</td>\n      <td>3</td>\n      <td>0.767803</td>\n      <td>0.689311</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "summary # best models are add, concat and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge   val_MAE       MAE  epoch  val_loss      loss\n0  concatenate  0.663808  0.587815      9  0.762902  0.602770\n1  dot_product  0.837408  0.819400      2  1.091396  1.055124\n2          add  0.678036  0.637935      3  0.775935  0.692228\n3    substract  0.675556  0.619166      5  0.767822  0.659461\n4     multiply  0.735127  0.525711      3  0.895239  0.478696\n5      average  0.673198  0.636541      3  0.767651  0.690644",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE</th>\n      <th>MAE</th>\n      <th>epoch</th>\n      <th>val_loss</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>0.663808</td>\n      <td>0.587815</td>\n      <td>9</td>\n      <td>0.762902</td>\n      <td>0.602770</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.837408</td>\n      <td>0.819400</td>\n      <td>2</td>\n      <td>1.091396</td>\n      <td>1.055124</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>0.678036</td>\n      <td>0.637935</td>\n      <td>3</td>\n      <td>0.775935</td>\n      <td>0.692228</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>0.675556</td>\n      <td>0.619166</td>\n      <td>5</td>\n      <td>0.767822</td>\n      <td>0.659461</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.735127</td>\n      <td>0.525711</td>\n      <td>3</td>\n      <td>0.895239</td>\n      <td>0.478696</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.673198</td>\n      <td>0.636541</td>\n      <td>3</td>\n      <td>0.767651</td>\n      <td>0.690644</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "# summary first run - best models are concat and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   concatenate  dot_product  add  substract  multiply  average\n0          147           54   70         70       147       70\n1          114          219  114        103        75      114\n2          103          195  147        147       134      219\n3           70          199   87        127        97      147\n4          219           87  103        114       219      103",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>concatenate</th>\n      <th>dot_product</th>\n      <th>add</th>\n      <th>substract</th>\n      <th>multiply</th>\n      <th>average</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>147</td>\n      <td>54</td>\n      <td>70</td>\n      <td>70</td>\n      <td>147</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114</td>\n      <td>219</td>\n      <td>114</td>\n      <td>103</td>\n      <td>75</td>\n      <td>114</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103</td>\n      <td>195</td>\n      <td>147</td>\n      <td>147</td>\n      <td>134</td>\n      <td>219</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>199</td>\n      <td>87</td>\n      <td>127</td>\n      <td>97</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>219</td>\n      <td>87</td>\n      <td>103</td>\n      <td>114</td>\n      <td>219</td>\n      <td>103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "# top 5 \n",
    "# 2 run\n",
    "top_5=pd.DataFrame()\n",
    "for n in mergemethod:\n",
    "    top_5[n]=predictions.nlargest(5,n).movie_index.values\n",
    "top_5\n",
    "# model concat and average recommend the same movies, the order is just different!\n",
    "# models sub and add recommend 4 out of 5 movies from model concat and average\n",
    "# movie 147 is recommended by all movies\n",
    "# movie 70,103,2019,114 is recommended by 4 out of 6 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   concatenate  dot_product  add  substract  multiply  average\n0           70          182   70        147       219      147\n1          147          199  147         70       226       70\n2          103           70  114        114        75      114\n3          219           75  222        222       179      202\n4          114          147   87        219       147       87",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>concatenate</th>\n      <th>dot_product</th>\n      <th>add</th>\n      <th>substract</th>\n      <th>multiply</th>\n      <th>average</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70</td>\n      <td>182</td>\n      <td>70</td>\n      <td>147</td>\n      <td>219</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>147</td>\n      <td>199</td>\n      <td>147</td>\n      <td>70</td>\n      <td>226</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103</td>\n      <td>70</td>\n      <td>114</td>\n      <td>114</td>\n      <td>75</td>\n      <td>114</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>219</td>\n      <td>75</td>\n      <td>222</td>\n      <td>222</td>\n      <td>179</td>\n      <td>202</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>114</td>\n      <td>147</td>\n      <td>87</td>\n      <td>219</td>\n      <td>147</td>\n      <td>87</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "top_5=pd.DataFrame()\n",
    "for n in mergemethod:\n",
    "    top_5[n]=predictions.nlargest(5,n).movie_index.values\n",
    "top_5\n",
    "# model concat and average recommend 3 same movies, model concat and add also\n",
    "# model add and average recommend 4 same movies, add and substract also\n",
    "# 147 is recommended by all models\n",
    "# models sub and add recommend 4 out of 5 movies from model concat and average\n",
    "# movie 147 is recommended by all movies\n",
    "# movie 70,103,2019,114 is recommended by 4 out of 6 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model concat and average recommend the same movies, the order is just different!\n",
    "# models sub and add recommend 4 out of 5 movies from model concat and average\n",
    "# movie 147 is recommended by all movies\n",
    "# movie 70,103,2019,114 is recommended by 4 out of 6 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we repeat the above steps but prepare the data for the model by using an Integer Encoding (from kaggle) instead of indexing the movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# loading train / test data\n",
    "def train_test_data_enc(ratings):\n",
    "    train=pd.read_pickle('/home/elena/Downloads/traindata.pkl')\n",
    "    test=pd.read_pickle('/home/elena/Downloads/testdata.pkl')\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(ratings['movie_id'])\n",
    "    train['movie_enc'] = label_encoder.transform(train['movie_id'])\n",
    "    test['movie_enc'] = label_encoder.transform(test['movie_id'])\n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc, test_enc=train_test_data_enc(ratings)\n",
    "y_train_enc=train_enc.rating\n",
    "y_test_enc=test_enc.rating\n",
    "X_train_enc=train_enc.drop('rating',axis=1)\n",
    "X_test_enc=test_enc.drop('rating',axis=1)\n",
    "movie_max_cat_value_enc=max(X_train_enc.movie_enc.max(), X_test_enc.movie_enc.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergemethod=['concatenate','dot_product','add','substract', 'multiply','average']\n",
    "summary_enc=pd.DataFrame(columns=['merge','val_MAE', 'MAE','epoch','val_loss', 'loss'])\n",
    "merge,epoch,val_MAE,MAE,loss,val_loss=[],[],[],[],[],[]\n",
    "# for prediction\n",
    "uid=1\n",
    "movies_test=X_test_enc.movie_enc[X_test_enc.user_id==uid]\n",
    "predictions=pd.DataFrame(movies_test.values)\n",
    "predictions.columns=['movie_index']\n",
    "# looping through the merging methods\n",
    "for m in mergemethod:\n",
    "    model=embedding_model(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value_enc,merging_method=m)\n",
    "    history=model.fit(x=[X_train_enc.user_id, X_train_enc.movie_enc], y=y_train_enc, batch_size=500,epochs=10, verbose=0, validation_data=[[X_test_enc.user_id, X_test_enc.movie_enc],y_test_enc], callbacks=[es])\n",
    "    # predicting for user uid\n",
    "    pred=model.predict([[uid]*len(movies_test),movies_test.index])\n",
    "    predictions[m]=pred\n",
    "    # collecting MAE's and loss\n",
    "    merge.append(m)\n",
    "    n=len(history.epoch)\n",
    "    epoch.append(n)\n",
    "    val_MAE.append(history.history['val_MAE'][n-1])\n",
    "    MAE.append(history.history['MAE'][n-1])\n",
    "    loss.append(history.history['loss'][n-1])\n",
    "    val_loss.append(history.history['val_loss'][n-1])\n",
    "summary_enc['merge']=merge \n",
    "summary_enc['val_MAE']=val_MAE \n",
    "summary_enc['epoch']=epoch\n",
    "summary_enc['MAE']=MAE \n",
    "summary_enc['loss']=loss \n",
    "summary_enc['val_loss']=val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge  val_MAE_x     MAE_x  val_MAE_y     MAE_y\n0  concatenate   0.673352  0.626355   0.673125  0.630098\n1  dot_product   0.834497  0.825047   0.833816  0.823366\n2          add   0.683223  0.628528   0.676729  0.616632\n3    substract   0.676290  0.627173   0.677572  0.627651\n4     multiply   0.731964  0.516169   0.732915  0.523372\n5      average   0.673574  0.617534   0.674682  0.635786",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE_x</th>\n      <th>MAE_x</th>\n      <th>val_MAE_y</th>\n      <th>MAE_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>0.673352</td>\n      <td>0.626355</td>\n      <td>0.673125</td>\n      <td>0.630098</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.834497</td>\n      <td>0.825047</td>\n      <td>0.833816</td>\n      <td>0.823366</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>0.683223</td>\n      <td>0.628528</td>\n      <td>0.676729</td>\n      <td>0.616632</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>0.676290</td>\n      <td>0.627173</td>\n      <td>0.677572</td>\n      <td>0.627651</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.731964</td>\n      <td>0.516169</td>\n      <td>0.732915</td>\n      <td>0.523372</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.673574</td>\n      <td>0.617534</td>\n      <td>0.674682</td>\n      <td>0.635786</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "# 1. run\n",
    "pd.merge(summary[['merge','val_MAE','MAE']],summary_enc[['merge','val_MAE','MAE']],on='merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         merge  val_MAE_x     MAE_x  val_MAE_y     MAE_y\n0  concatenate   0.675439  0.637787   0.678883  0.638073\n1  dot_product   0.787453  0.456959   0.801555  0.456958\n2          add   0.673487  0.613035   0.678191  0.636344\n3    substract   0.676568  0.627759   0.678331  0.626237\n4     multiply   0.726129  0.535156   0.736653  0.510700\n5      average   0.676141  0.635752   0.677634  0.621122",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge</th>\n      <th>val_MAE_x</th>\n      <th>MAE_x</th>\n      <th>val_MAE_y</th>\n      <th>MAE_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>concatenate</td>\n      <td>0.675439</td>\n      <td>0.637787</td>\n      <td>0.678883</td>\n      <td>0.638073</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dot_product</td>\n      <td>0.787453</td>\n      <td>0.456959</td>\n      <td>0.801555</td>\n      <td>0.456958</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>add</td>\n      <td>0.673487</td>\n      <td>0.613035</td>\n      <td>0.678191</td>\n      <td>0.636344</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>substract</td>\n      <td>0.676568</td>\n      <td>0.627759</td>\n      <td>0.678331</td>\n      <td>0.626237</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multiply</td>\n      <td>0.726129</td>\n      <td>0.535156</td>\n      <td>0.736653</td>\n      <td>0.510700</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>average</td>\n      <td>0.676141</td>\n      <td>0.635752</td>\n      <td>0.677634</td>\n      <td>0.621122</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "pd.merge(summary[['merge','val_MAE','MAE']],summary_enc[['merge','val_MAE','MAE']],on='merge')\n",
    "# model with indexing stays a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now predict movies and time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_data(ratings)\n",
    "y_train=train[['rating','unix_timestamp']]\n",
    "y_test=test[['rating','unix_timestamp']]\n",
    "X_train=train.drop(['rating','unix_timestamp'], axis=1)\n",
    "X_test=test.drop(['rating','unix_timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing unix_timestamp\n",
    "max_train=y_train.unix_timestamp.max()\n",
    "y_train['norm']=[float(i)/max_train for i in y_train.unix_timestamp]\n",
    "max_test=y_test.unix_timestamp.max()\n",
    "y_test['norm']=[float(i)/max_test for i in y_test.unix_timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train=y_train.unix_timestamp.min()\n",
    "y_train['norm_min']=[float(i)/max_train for i in y_train.unix_timestamp]\n",
    "min_test=y_test.unix_timestamp.min()\n",
    "y_test['norm_min']=[float(i)/max_test for i in y_test.unix_timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1.0, 0.5385275978108841, 1.0, 0.5385128227888003)"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "y_train.norm.max(),y_train.norm.min(), y_test.norm.max(),y_test.norm.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the models used\n",
    "hidden_units = (100,50) #same as in pytorch model\n",
    "movie_embedding_dim = 50 #same as in pytorch model\n",
    "user_embedding_dim = 50  #same as in pytorch model\n",
    "user_max_cat_value = ratings.user_id.max()\n",
    "movie_max_cat_value=X_test.movie_index.max()\n",
    "es=EarlyStopping(monitor='val_MAE', min_delta=0, patience=0, verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
    "# the model \n",
    "#\n",
    "#\n",
    "def embedding_model_mult_out(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value,merging_method):\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    # Embeddings\n",
    "    user_embedded = Embedding(user_max_cat_value+1, user_embedding_dim, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "    movie_embedded = Embedding(movie_max_cat_value+1, movie_embedding_dim, \n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "    # merging the embeddings\n",
    "    if merging_method=='concatenate':\n",
    "        merged = Concatenate()([user_embedded, movie_embedded])\n",
    "    if merging_method=='dot_product':\n",
    "        merged =Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedded, movie_embedded])\n",
    "    if merging_method=='add':\n",
    "        merged =Add()([user_embedded, movie_embedded])\n",
    "    if merging_method=='substract':\n",
    "        merged=Subtract()([user_embedded, movie_embedded])\n",
    "    if merging_method=='multiply':\n",
    "        merged=Multiply()([user_embedded, movie_embedded])\n",
    "    if merging_method=='average':\n",
    "        merged=Average()([user_embedded, movie_embedded])\n",
    "    out = Flatten()(merged)\n",
    "\n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "        out = Dense(n_hidden, activation='relu')(out)\n",
    "\n",
    "    #Two outputs: our predicted rating and unix_timestamp\n",
    "    out_movie = Dense(1, activation='linear', name='movies_pred')(out)\n",
    "    out_time = Dense(1, activation='relu', name='time_pred')(out)\n",
    "    model = Model(inputs = [user_id_input, movie_id_input],outputs = [out_movie, out_time])\n",
    "    model.compile(optimizer = 'Adam',loss='MSE',metrics=['MAE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=embedding_model_mult_out(hidden_units, user_embedding_dim, user_max_cat_value, movie_embedding_dim, movie_max_cat_value_enc,merging_method='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 75627 samples, validate on 25209 samples\nEpoch 1/10\n - 4s - loss: 3.3882 - movies_pred_loss: 3.2255 - time_pred_loss: 0.1500 - movies_pred_MAE: 1.3145 - time_pred_MAE: 0.2927 - val_loss: 0.8155 - val_movies_pred_loss: 0.7845 - val_time_pred_loss: 0.0301 - val_movies_pred_MAE: 0.6857 - val_time_pred_MAE: 0.1394\nEpoch 2/10\n - 3s - loss: 0.7549 - movies_pred_loss: 0.7284 - time_pred_loss: 0.0261 - movies_pred_MAE: 0.6562 - time_pred_MAE: 0.1300 - val_loss: 0.7832 - val_movies_pred_loss: 0.7630 - val_time_pred_loss: 0.0195 - val_movies_pred_MAE: 0.6738 - val_time_pred_MAE: 0.1142\nEpoch 3/10\n - 3s - loss: 0.7013 - movies_pred_loss: 0.6895 - time_pred_loss: 0.0118 - movies_pred_MAE: 0.6360 - time_pred_MAE: 0.0863 - val_loss: 0.7706 - val_movies_pred_loss: 0.7639 - val_time_pred_loss: 0.0063 - val_movies_pred_MAE: 0.6709 - val_time_pred_MAE: 0.0624\nEpoch 4/10\n - 3s - loss: 0.6773 - movies_pred_loss: 0.6734 - time_pred_loss: 0.0044 - movies_pred_MAE: 0.6262 - time_pred_MAE: 0.0511 - val_loss: 0.7681 - val_movies_pred_loss: 0.7642 - val_time_pred_loss: 0.0033 - val_movies_pred_MAE: 0.6708 - val_time_pred_MAE: 0.0444\nEpoch 5/10\n - 3s - loss: 0.6655 - movies_pred_loss: 0.6634 - time_pred_loss: 0.0024 - movies_pred_MAE: 0.6204 - time_pred_MAE: 0.0371 - val_loss: 0.7679 - val_movies_pred_loss: 0.7651 - val_time_pred_loss: 0.0021 - val_movies_pred_MAE: 0.6725 - val_time_pred_MAE: 0.0336\nEpoch 6/10\n - 3s - loss: 0.6580 - movies_pred_loss: 0.6572 - time_pred_loss: 0.0019 - movies_pred_MAE: 0.6165 - time_pred_MAE: 0.0321 - val_loss: 0.7655 - val_movies_pred_loss: 0.7627 - val_time_pred_loss: 0.0020 - val_movies_pred_MAE: 0.6708 - val_time_pred_MAE: 0.0342\nEpoch 7/10\n - 3s - loss: 0.6510 - movies_pred_loss: 0.6491 - time_pred_loss: 0.0015 - movies_pred_MAE: 0.6126 - time_pred_MAE: 0.0284 - val_loss: 0.7694 - val_movies_pred_loss: 0.7670 - val_time_pred_loss: 0.0016 - val_movies_pred_MAE: 0.6732 - val_time_pred_MAE: 0.0291\nEpoch 8/10\n - 3s - loss: 0.6452 - movies_pred_loss: 0.6435 - time_pred_loss: 0.0016 - movies_pred_MAE: 0.6090 - time_pred_MAE: 0.0295 - val_loss: 0.7672 - val_movies_pred_loss: 0.7646 - val_time_pred_loss: 0.0019 - val_movies_pred_MAE: 0.6663 - val_time_pred_MAE: 0.0322\nEpoch 9/10\n - 3s - loss: 0.6356 - movies_pred_loss: 0.6346 - time_pred_loss: 0.0016 - movies_pred_MAE: 0.6036 - time_pred_MAE: 0.0304 - val_loss: 0.7614 - val_movies_pred_loss: 0.7588 - val_time_pred_loss: 0.0018 - val_movies_pred_MAE: 0.6662 - val_time_pred_MAE: 0.0313\nEpoch 10/10\n - 3s - loss: 0.6217 - movies_pred_loss: 0.6196 - time_pred_loss: 0.0019 - movies_pred_MAE: 0.5955 - time_pred_MAE: 0.0329 - val_loss: 0.7699 - val_movies_pred_loss: 0.7669 - val_time_pred_loss: 0.0023 - val_movies_pred_MAE: 0.6764 - val_time_pred_MAE: 0.0360\n"
    }
   ],
   "source": [
    "history=model.fit(x=[X_train.user_id, X_train.movie_index], y=[y_train.rating,y_train.norm], batch_size=500,epochs=10, verbose=2, validation_data=[[X_test.user_id, X_test.movie_index],[y_test.rating,y_test.norm]], callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.5955444, 0.6763771772384644, 0.032870516, 0.03596564009785652)"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "history.history['movies_pred_MAE'][9], history.history['val_movies_pred_MAE'][9], history.history['time_pred_MAE'][9], history.history['val_time_pred_MAE'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid=1\n",
    "movies_test=X_test.movie_index[X_test.user_id==uid]\n",
    "predictions=pd.DataFrame(movies_test.values)\n",
    "predictions.columns=['movie_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_movies=model.predict([[uid]*len(movies_test),movies_test.index]) # returns a list with 2 columns\n",
    "predictions['rating_pred']=pred_movies[0]\n",
    "predictions['time_pred']=pred_movies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   movie_index  rating_pred  time_pred\n0          226     4.399261   0.620912\n1          149     4.033945   0.622854\n2           87     4.492454   0.592156\n3           35     4.153248   0.556509\n4          134     4.295627   0.617552",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_index</th>\n      <th>rating_pred</th>\n      <th>time_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>226</td>\n      <td>4.399261</td>\n      <td>0.620912</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>149</td>\n      <td>4.033945</td>\n      <td>0.622854</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>87</td>\n      <td>4.492454</td>\n      <td>0.592156</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35</td>\n      <td>4.153248</td>\n      <td>0.556509</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>134</td>\n      <td>4.295627</td>\n      <td>0.617552</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 175
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ee84a77e33a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtop_5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rating_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtop_5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "top_5=pd.DataFrame()\n",
    "top_5['pred']=predictions.nlargest(5,'rating_pred').movie_index.values\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}